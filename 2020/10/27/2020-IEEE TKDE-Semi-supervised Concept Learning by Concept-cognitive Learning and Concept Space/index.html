<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="个人博客，记录成长的点滴。">
  <meta name="author" content="peerless">
  <meta name="keywords" content="">
  <title>2020-IEEE TKDE-Semi-supervised Concept Learning by Concept-cognitive Learning and Concept Space - peerless</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>peerless</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-10-27 09:18">
      2020年10月27日 上午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      8.1k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      97
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1 id="Semi-supervised-Concept-Learning-by-Concept-cognitive-Learning-and-Concept-Space"><a href="#Semi-supervised-Concept-Learning-by-Concept-cognitive-Learning-and-Concept-Space" class="headerlink" title="Semi-supervised Concept Learning by Concept-cognitive Learning and Concept Space"></a>Semi-supervised Concept Learning by Concept-cognitive Learning and Concept Space</h1><div class="note note-primary">
            <p>半监督学习、概念认知学习、增量学习</p>
          </div> 
<a id="more"></a>
<!-- <p class='note note-info'>论文、属性探索</p> -->
<h2 id="论文基本信息"><a href="#论文基本信息" class="headerlink" title="论文基本信息"></a>论文基本信息</h2><pre><code>        1. 作者：Yunlong Mi, Wenqi Liu, Yong Shi, and Jinhai Li。
           2. 期刊：IEEE Transactions on Knowledge and Data Engineering(IEEE TKDE)。

              1. SCI： 2区。
</code></pre><p>​                  2. CCF： A类。<br>​                  3. IF：4.935。</p>
<p>​            3. 时间：2020/7/21。</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ol>
<li>提出了一种新的基于概念空间的动态半监督学习方法(SSL)—半监督概念学习方法(S2CL)，该方法利用层次概念来表示知识。</li>
<li>为了充分利用全局和局部的概念信息，进一步提出一种扩展版本的S2CL(即${S2CL}^{\alpha}$)用于概念学习。</li>
</ol>
<ul>
<li>给出了基于正则决策形式背景的$S2CL$与${S2CL}^{\alpha}$一些新的相关理论。</li>
<li>设计了一个新的SSL框架，并给出了相应的$S2CL$与${S2CL}^{\alpha}$算法。</li>
<li>在不同的数据集上进行实验(包括概念分类和大量未标注数据下的增量学习)，验证方法的有效性。</li>
</ul>
<h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1 INTRODUCTION"></a>1 INTRODUCTION</h2><ol>
<li>由于许多实际任务仍然缺乏足够数量的标注数据，这导致传统的监督学习方法在这些任务中性能较差。</li>
</ol>
<p>因为==不能充分利用大量未标注数据背后的信息==，这意味着采用半监督假设与数据的分布一致时，==半监督学习(SSL)可以提高学习精度$^{[1]}$==。</p>
<p>2.为了充分利用未标注数据背后的信息，人们从不同的角度提出了多种将未标注数据集成到不同的分类器的SSL方法$^{[2-7]}$。</p>
<p>3.为了实现对少量已标注数据集的动态分类，需要对标准的SSL算法做出重大改变以获得更好的性能。</p>
<p>然而 ，存在==两个主要问题==：</p>
<ul>
<li>重构经典的SSL算法以适应新增的数据并非易事。</li>
<li>经典的SSL算法对数据敏感，无法在增量过程中利用标记信息，这将会影响SSL算法的性能。</li>
</ul>
<p>因此==通过更新概念空间来解决动态过程的概念认知学习(CCL)$^{[8,9]}$==可能是一个不错的选择。一般从概念学习$^{[10]}$、粒计算(GrC)$^{[11-13]}$和动态过程三个方面进行讨论。</p>
<p>概念学习：人们从不同的角度研究了一些未知概念的学习。</p>
<ul>
<li>从不同层次$^{[14]}$解释解释概念学习。</li>
<li>从认知角度$^{[15,16]}$获取概念。</li>
<li>通过构建不同的概念体系$^{[17-19]}$获得新概念。</li>
<li>通过概念格$^{[20,21]}$中的正反例实现基于概念的学习。</li>
</ul>
<p>粒计算(GrC)：表示数据集通常可以划分为不同的粒度以满足不同的需求，并已融合入各种领域。如形式概念分析(FCA)$^{[22,23]}$、粗糙集$^{[24]}$、大数据$^{[25,26]}$、机器学习$^{[8,25]}$和概念学习$^{[8,9,15,27,28]}$。</p>
<p>动态过程：数据挖掘的重要步骤之一$^{[26]}$，已存在各种增量学习方法$^{[7,29-34]}$。CCL就是这样一种方法，它以概念为知识载体，通过模仿人类的学习过程，自然地完成增量学习任务。                                                                                                                                                                                         </p>
<p>4.到目前为止，已经从认知关系的CCL$^{[37]}$和近似CCL$^{[9,15]}$等不同的角度提出了不同的相关的CCL系统$^{[14,35,36]}$。</p>
<p>特别地，为了获得动态环境下的泛化能力，提出了一种基于正则决策形式背景$^{[8,27]}$的CCL模型(CCLM)。然而这些相关的CCL系统都==缺乏概念分类能力==。</p>
<p>例如：如何将GrC与认知过程和MapReduce框架相结合来学习近似概念$^{[9]}$。</p>
<p>​            提出了一个泛化的CCL框架，还需要进一步的研究$^{[8]}$。</p>
<p>同时，当前的CCLM及其扩展版本(即C3LM)也无法解决SSL的问题。            </p>
<p>另外，基于概念的正反例学习方法$^{[20,21]}$由于主要考虑静态学习的情况，还不能实现动态分类任务。</p>
<p>因此==如何将CCL引入SSL来实现增量学习==是本研究的一个挑战。</p>
<p>5.结构化知识在人类知识组织中起重要的作用，许多关于知识表示的研究都致力于这一主题。</p>
<p>如知识层次结构$^{[39]}$、知识粒度结构$^{[14]}$以及基于概念层次的概念聚类$^{[40,41]}$。</p>
<p>此外，FCA$^{[42]}$通过层次化的概念结构来组织知识，为结构化知识表示和概念学习提供了一种有用的方法。换句话说就是，在FCA$^{[43,44]}$中构建分层概念结构时，允许从数据构建中间知识。</p>
<p>6.概念聚类试图提供一个或几个概念作为对所获得的聚类的解释$^{[45]}$，它由两个最主要的任务组成，即概念分类和概念发现$^{[46]}$。</p>
<p>但与[41]类似，本文只关注==层次概念结构在用于概念分类的特殊概念聚类(即FCA)中的作用==。</p>
<p>7.事实上，为了满足不同的需求，FCA已经被广泛地集成到概念聚类中。</p>
<p>例如：因子空间的概念形成$^{[47]}$、构建概念层次$^{[48]}$、自动本体生成$^{[48]}$、以及基于案例的分层学习$^{[41]}$。</p>
<p>8.同时，S2CL是一种借助FCA中知识层次结构的增量式概念学习算法，它不同于侧重于对单链接层次聚类的稳定性和收敛性进行公理化描述的稳定聚类方法$^{[49]}$。</p>
<p>9.这些关于聚类方法的相关研究，如层次聚类方法$^{[49]}$和基于密度的流聚类算法$^{[50]}$，进一步证明了聚类过程将有利于知识发现，以及将概念聚类引入到我们方法中的可行性。</p>
<p>然而，就我们所知，基于概念结构表征的半监督概念学习还没有相关的研究。</p>
<p>因此，如何==通过概念聚类将概念结构信息集成到SSL==中是我们工作中的另一个挑战。</p>
<p>10.本文提出了一种新的用于SSL的半监督概念学习模型(S2CL)，为实现具有层次化概念知识的复杂分类任务提供参考。此外，为了提高分类性能，我们的方法(包括S2CL及其扩展版本${S2CL}^{\alpha}$)还加入了概念结构信息和Top-K集相似度$^{[51-53]}$。</p>
<p>本文主要贡献如下：</p>
<ol>
<li>首先提出了一种新的基于正则决策形式背景的SSL理论，并将CCL和概念聚类相结合，提出了一种增量SSL的新框架。</li>
<li>我们的方法不是直接将所有未标记的数据输入到模型中，而是通过模仿人类的认知机制来自然地完成动态过程。这样可以避免了昂贵的计算。换言之，所提出的方法也可以被称为增量学习方法，它可以随着时间的推移进行更新，而不需要重构。</li>
<li>最后，与一些以特征向量表示为特征的标准SSL方法相比，我们的方法是基于结构化知识表示库(即概念空间)设计的。此外，我们在真实数据上的实验表明，所提出的方法能够在少量标注数据的情况下获得良好的概念分类和增量学习性能。</li>
</ol>
<h2 id="2-RELATED-WORK"><a href="#2-RELATED-WORK" class="headerlink" title="2 RELATED WORK"></a>2 RELATED WORK</h2><h3 id="2-1-Related-Notations"><a href="#2-1-Related-Notations" class="headerlink" title="2.1 Related Notations"></a>2.1 Related Notations</h3><p>Instance $x$：一个对象$x$，信息系统的输入项。</p>
<p>Class $y$：正则决策形式背景的决策属性值。</p>
<p>Dataset $X = \{ (x_i, y_i) \}_{i=1}^{n}$：非空有限对象集合G。</p>
<p>Label set $\mathcal{Y} = \{ 1,2, \cdots, l \}$：正则决策形式背景的决策属性集D。</p>
<p>Labeled dataset $S_L = \{ (x_i, y_i) \}_{i=1}^{l^{\prime}}$：正则决策形式背景中具有决策属性信息的对象集。</p>
<p>Unlabeled dataset $S_U = \{ x_j \}_{j = l^{\prime} + 1}^{m}$：正则决策形式背景中不具有决策属性信息的对象集。</p>
<h3 id="2-2-CCL"><a href="#2-2-CCL" class="headerlink" title="2.2 CCL"></a>2.2 CCL</h3><p>G：对象集，M：属性集。</p>
<p>$2^G$：对象幂集，$2^M$：属性幂集。</p>
<p>两个值映射：$\mathcal{F}: 2^G \rightarrow 2^M$ 和 $\mathcal{H}: 2^M \rightarrow 2^G$。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027174249832.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027174249832.png" srcset="/img/loading.gif" alt></p>
<p>考虑新型冠状病毒确诊患者的共性症状，即研究对象是确诊患者，属性为新型冠状病毒的感染症状。</p>
<p>(i) $X_1 \subseteq X_2 \Rightarrow  \mathcal{F}(X_2) \subseteq \mathcal{F}(X_1)$，即确诊患者越多，其共性症状越少。</p>
<p>(ii) $\mathcal{F}(X_1) \cap \mathcal{F}(X_2)  \subseteq \mathcal{F}(X_1 \cup X_2)$，即对于寻找患者的共性症状，整体识别比分开依次完成更容易实现。</p>
<p>可以理解为，将所有患者集中观察其共同症状要比分开观察更容易。</p>
<p>(iii) $\mathcal{H}(A) = \{ x\in G\ |\ A\subseteq \mathcal{F}({x})  \}$，即对于疑似病例，只有具备关键的共性症状才需要进一步判断其是否为新型冠状病毒患者。</p>
<p>==粒概念==(简单概念)：对于任意的$x\in G$ 和 $a\in M$，有序对$(\mathcal{HF}(x), \mathcal{F}(x))$和$(\mathcal{H}(a), \mathcal{FH}(a))$被称为认知算子$\mathcal{F}$和$\mathcal{H}$下的粒概念。</p>
<p>注意：==在CCL系统中使用概念而不是对象作为信息载体==。</p>
<p>==概念空间==(所有粒概念的集合)：$G_{\mathcal{FH}} = \{ (\mathcal{HF}(x), \mathcal{F}(x))\ |\ x\in G \} \cup \{ (\mathcal{H}(a), \mathcal{FH}(a))\ |\ a\in M \}$。</p>
<p>由于CCL系统中的学习过程通常是在动态环境下完成的。这意味着在第$i-1$阶段的对象集$G_{i-1}$中输入新的对象可以得到第$i$阶段的对象集$G_i$。其中$\mathcal{F}_{i-1}$和$\mathcal{H}_{i-1}$分别为第$i-1$阶段的认知算子，相应的概念空间为$G_{\mathcal{F_{i-1}H_{i-1}}}$。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027194043193.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027194043193.png" srcset="/img/loading.gif" alt></p>
<p>由定义1可以获得认知算子$\mathcal{F}$和$\mathcal{H}$下的初始概念空间。</p>
<p>由定义2可以基于当前概念空间完成学习过程。</p>
<h3 id="2-3-Regular-Formal-Decision-Context"><a href="#2-3-Regular-Formal-Decision-Context" class="headerlink" title="2.3 Regular Formal Decision Context"></a>2.3 Regular Formal Decision Context</h3><p>G：对象集，D：决策属性集。</p>
<p>$2^G$：对象幂集，$2^D$：决策属性幂集。</p>
<p>两个值映射：$\widetilde{\mathcal{F}}: 2^G \rightarrow 2^D$ 和 $\widetilde{\mathcal{H}}: 2^D \rightarrow 2^G$。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027201610790.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027201610790.png" srcset="/img/loading.gif" alt></p>
<p>实际上，性质1表明，当对象$x$满足$X_1 = \mathcal{HF}(x)$和$K = \mathcal{FH}(k)$时，对象$x$可以由单个标签$k$来标注。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027204535376.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027204535376.png" srcset="/img/loading.gif" alt></p>
<p>由于决策子属性集合$D_k$在正则决策形式背景下包含单个标记信息。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027204842657.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027204842657.png" srcset="/img/loading.gif" alt></p>
<p>定义4说明，一个对象集可以根据决策属性信息分解成多个子对象集。</p>
<p>此外，根据范畴表示公理$^{[54]}$，我们有充分的理由相信</p>
<ol>
<li>每个子概念空间由不同的概念组成，</li>
<li>其中不同的概念可以通过标签集合$\mathcal{Y}$中不同类别的标签来构成。</li>
</ol>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027210916523.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027210916523.png" srcset="/img/loading.gif" alt></p>
<p>因此，下文只讨论正则决策形式背景下与单个类标签相关联的子概念空间的情况。</p>
<p>尽管如此，但是需要指出的是，上述讨论是建立在一个强有力的假设的基础上的：所有样本均有正确的标签信息。</p>
<p>也就是说，它们不能直接处理没有考虑到标签信息的SSL问题。因此，探索一些新的理论来应对半监督概念学习是非常必要的。</p>
<h2 id="3-PROPOSED-S2CL"><a href="#3-PROPOSED-S2CL" class="headerlink" title="3 PROPOSED S2CL"></a>3 PROPOSED S2CL</h2><p style="text-indent:2em">我们首先在3.1小节中介绍有标签数据的初始概念空间，然后在3.2小节、3.3小节和3.4小节中分别介绍无标签数据的概念认知过程、S2CL的概念识别和理论分析。最后，为了更清楚地理解建议的S2CL，我们给出了它的整个过程，并在第3.5节讨论了计算成本。</p>

<h3 id="3-1-Concept-Space-with-Structural-Information"><a href="#3-1-Concept-Space-with-Structural-Information" class="headerlink" title="3.1 Concept Space with Structural Information"></a>3.1 Concept Space with Structural Information</h3><p>与标记$k$相关联的正则子对象决策形式背景</p>
<p>子对象集$G^k$下的条件子对象认知算子：$\mathcal{F^k}, \mathcal{H^k}$。</p>
<p>子对象集$G^k$下的决策子对象认知算子：$\mathcal{\widetilde{F}^k}, \mathcal{\widetilde{H}^k}$。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027212152476.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027212152476.png" srcset="/img/loading.gif" alt></p>
<p> 条件子对象形式背景下的面向对象的条件概念与面向属性的条件概念</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027212857576.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027212857576.png" srcset="/img/loading.gif" alt></p>
<p>条件子对象形式背景下的面向对象的条决策概念与面向属性的决策概念</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027213053996.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027213053996.png" srcset="/img/loading.gif" alt></p>
<p>正则子对象决策形式背景下的条件概念空间和决策概念空间</p>
<script type="math/tex; mode=display">
\begin{align*}
G_{\mathcal{F^k H^k}} = &\ OG_{\mathcal{F^k H^k}} \cup AG_{\mathcal{F^k H^k}} \newline
= &\ \{ (\mathcal{H^k F^k}(x), \mathcal{F^k}(x))\ |\ x\in G^k  \} \cup \{ (\mathcal{H^k}(a), \mathcal{F^k H^k}(a))\ |\ a\in M \} \newline
\newline
G_{\mathcal{\widetilde{F}^k \widetilde{H}^k}} = &\ OG_{\mathcal{\widetilde{F}^k \widetilde{H}^k}} \cup AG_{\mathcal{\widetilde{F}^k \widetilde{H}^k}} \newline
= &\ \{ (\mathcal{\widetilde{H}^k \widetilde{F}^k}(x), \mathcal{\widetilde{F}^k}(x))\ |\ x\in G^k  \} \cup \{ (\mathcal{\widetilde{H}^k}(k^{\prime}), \mathcal{\widetilde{F}^k \widetilde{H}^k}(k^{\prime}))\ |\ k^{\prime}\in D \}
\end{align*}</script><p>这意味着可以利用面向对象的概念和面向属性的概念来构造子对象集$G^k$的概念空间。</p>
<p>条件概念空间与决策概念空间中概念的构成。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027222113798.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027222113798.png" srcset="/img/loading.gif" alt></p>
<p>概念空间：$G_{\mathcal{F^k H^k}}^{\diamond}$和$G_{\mathcal{\widetilde{F}^k \widetilde{H}^k}}^{\diamond}$。</p>
<p>面向属性的条件概念空间：$AG_{\mathcal{F^k H^k}}$</p>
<p>面向属性的决策概念空间：$AG_{\mathcal{\widetilde{F}^k \widetilde{H}^k}}$。</p>
<p>同时，初始化：$G_{\mathcal{F^k H^k}}^{\diamond} = AG_{\mathcal{F^k H^k}}$和$G_{\mathcal{\widetilde{F}^k \widetilde{H}^k}}^{\diamond} = AG_{\mathcal{\widetilde{F}^k \widetilde{H}^k}}$。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027234758350.png" srcset="/img/loading.gif" class><img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027234820257.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027234758350.png" srcset="/img/loading.gif" alt><br><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201027234820257.png" srcset="/img/loading.gif" alt></p>
<p>性质2说明，当$\mathcal{F^k}(x) = \mathcal{F^k H^k}(a)$和$\mathcal{\widetilde{F}^k}(x) = \mathcal{\widetilde{F}^k \widetilde{H}^k}(k^{\prime})$时，我们不需要向文献[27]那样构造概念$(\mathcal{H^k F^k}(x), \mathcal{F^k}(x))$和$(\mathcal{\widetilde{H}^k \widetilde{F}^k}(x), \mathcal{\widetilde{F}^k}(x))$，因此，利用这种方法最终我们可以得到$G_{\mathcal{F^k H^k}} = G_{\mathcal{F^k H^k}}^{\diamond}$和$G_{\mathcal{\widetilde{F}^k \widetilde{H}^k}} = G_{\mathcal{\widetilde{F}^k \widetilde{H}^k}}^{\diamond}$</p>
<p>为了方便，将带标记的数据集$S_L$以$G_0$指定，则==初始的概念空间为$G_{\mathcal{F_0 H_0}}$和$G_{\mathcal{\widetilde{F}_0 \widetilde{H}_0}}$==。</p>
<p>初始的概念空间阶段，如果将对象集$G^k$以$G_0^k$代替，则相应的认知算子$\mathcal{F}_0^k,\mathcal{H}_0^k$和$\mathcal{\widetilde{F}_0^k}, \mathcal{\widetilde{H}_0^k}$。</p>
<h3 id="3-2-Cognitive-Process-with-Unlabeled-Data-in-Concept-Learning"><a href="#3-2-Cognitive-Process-with-Unlabeled-Data-in-Concept-Learning" class="headerlink" title="3.2 Cognitive Process with Unlabeled Data in Concept Learning"></a>3.2 Cognitive Process with Unlabeled Data in Concept Learning</h3><p>在概念认知的过程中，假设通过新增加一个新的对象而不是多个对象来对更新概念空间。</p>
<p>每一步只增加一个对象$x$：$\triangle G_i = \{ x_i \}$。</p>
<p>未标记的数据集$S_U$：$\triangle G = \{ \triangle G_0, \triangle G_1, \cdots, \triangle G_{n-1} \} = \{ x_0, x_1, \cdots, x_{n-1} \}$。</p>
<p>不同于文献[27]，由于没有标记信息，因此我们假定：一个对象$x$与一个虚拟的标记$k^*$相关联。</p>
<p>然后对新输入的数据$\triangle G_{i-1}^{k^<em>} = G_{i}^{k^</em>} - G_{i-1}^{k^*}$使用条件子对象认知算子和决策子对象认知算子则有：</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028003142792.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028003142792.png" srcset="/img/loading.gif" alt></p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028003548523.png" srcset="/img/loading.gif" class><img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028003634392.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028003548523.png" srcset="/img/loading.gif" alt><br><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028003634392.png" srcset="/img/loading.gif" alt></p>
<p>定理2说明了在添加实例时如何更新概念空间。</p>
<p>但是概念识别是非常困难的，因为我们不能直接识别每个实例$x$的真实类别标签。也就是说，与最初的概念空间生成不同的是，当输入没有标签信息的新对象时，哪个子概念空间会被更新仍然是一个谜。</p>
<h3 id="3-3-Concept-Cognition"><a href="#3-3-Concept-Cognition" class="headerlink" title="3.3 Concept Cognition"></a>3.3 Concept Cognition</h3><p>对于新输入的对象$x$，由于$|\triangle G_i^{k^<em>}| = 1$，所以概念$(\mathcal{H}_{\triangle G_i^{k^</em>}}^{k^<em>} \mathcal{F}_{\triangle G_i^{k^</em>}}^{k^<em>}(x), \mathcal{F}_{\triangle G_i^{k^</em>}}^{k^<em>}(x)) = (\{ x \}, \mathcal{F}_{\triangle G_i^{k^</em>}}^{k^*}(x))$</p>
<p>同时，为了满足大量的未标记数据的需求，提出了一种新的概念学习相似度度量方法。事实上，良好的概念评估相似性是S2CL成功的关键。</p>
<p>状态(i-1)下的全局信息与局部信息。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028005546979.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028005546979.png" srcset="/img/loading.gif" alt></p>
<p>更一般地，考虑处于(i-1)状态下的整个概念空间。</p>
<p>状态(i-1)下的全局信息和局部信息为</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028005958929.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028005958929.png" srcset="/img/loading.gif" alt></p>
<p>新输入的概念$C = (\{ x \}, \mathcal{F}_{\triangle G_i^{k^<em>}}^{k^</em>}(x))$与任意已知概念间得到概念相似度(concept similarity(CS))为</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028010738594.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028010738594.png" srcset="/img/loading.gif" alt></p>
<p>事实上，当α=0.5时，等式(15)退化为Jaccard相似度$^{[39]、[55]}$。</p>
<p>根据样本分离公理$^{[54]}$，对于任何实例，总是存在与其最相似的唯一类。</p>
<p>因此，对于实例$x$，类向量可以通过如下步骤获得：</p>
<ol>
<li><p>先计算出给定概念与一个子概念空间任意概念的相似度，并从每个子概念空间中选取该概念空间最大的概念相似度。</p>
</li>
<li><p>构成最大的类向量来评估类分布。平均类向量类似。</p>
</li>
</ol>
<p>注意：通过将概念认知过程与结构化概念相似度$θ_j$相结合而设计的SSL方法被称为半监督概念学习方法，为了方便起见，将其缩写为S2CL。同时，通过充分利用概念空间中的全局和局部概念信息(即结构概念相似度$θ_j^I$)，进一步提出了S2CL的扩展版本。为简洁起见，在不存在混淆的情况下，我们也将其写为${S2CL}^{\alpha}$。</p>
<h3 id="3-4-Theoretical-Analysis"><a href="#3-4-Theoretical-Analysis" class="headerlink" title="3.4  Theoretical Analysis"></a>3.4  Theoretical Analysis</h3><p>从本质上讲，α主要反映了集合$A^∗−B_j$和集合$B_j−A^∗$中不同特征对整体概念相似度的影响。因此，讨论如何在每个数据集上选择合适的α是非常重要的。</p>
<p>状态(i-1)下不同$\alpha_r$的概念空间为</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028012736354.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028012736354.png" srcset="/img/loading.gif" alt></p>
<p>状态(i-1)下概念相似度为</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028013322891.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028013322891.png" srcset="/img/loading.gif" alt="image-20201028013322891"></p>
<p>此外，受文献[54]的启发，给定概念$C_i$与类空间$G_{\mathcal{F_{i-1},H_{i-1}}}^{\alpha_r,k}$之间的相似度为</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028013810551.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028013810551.png" srcset="/img/loading.gif" alt></p>
<p>根据Top-K$^{[51]}$集合相似度得到的目标函数为</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028014057792.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028014057792.png" srcset="/img/loading.gif" alt></p>
<p>我们的目标是利用概念结构信息获取最优的概念空间。</p>
<h3 id="3-5-Framework-and-Computational-Complexity-Analysis"><a href="#3-5-Framework-and-Computational-Complexity-Analysis" class="headerlink" title="3.5 Framework and Computational Complexity Analysis"></a>3.5 Framework and Computational Complexity Analysis</h3><p>为简明起见，我们可以认为有三类需要预测，S2CL的整个学习过程</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028081317553.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028081317553.png" srcset="/img/loading.gif" alt></p>
<p>1.1我们首先获得相应的正规形式决策形式背景。然后，基于认知算子构造具有概念结构信息的初始概念空间(包括条件概念空间及其对应的决策概念空间)。</p>
<p>具体地说，条件概念空间包含三个子概念空间，每个子概念空间由不同的概念组成。在条件概念空间中存在三个子概念空间，对应于三个类别，每个子概念空间包含两种不同类型的概念，即面向对象的条件概念(红色)和面向属性的条件概念(黑色)。</p>
<p>1.2如图1的第一阶段所示，每个子概念空间还与相应的决策概念空间中的一个决策概念相关联。</p>
<p>1.3对于任何新输入的未标注数据，首先利用它们形成概念，然后通过概念识别来完成概念认知过程。</p>
<p>1.4S2CL(或$S2CL^α$)试图根据不同参数$α_r(r=1，2，\cdots, n)$下的概念识别和概念认知过程来学习最优概念空间。换言之，S2CL(或$S2CL^α$)的目标是通过概念认知过程寻找一个合适的概念空间来表示潜在的数据分布。</p>
<p>2.在预测阶段，给定一个实例，最终的概念空间可以通过使用CS度$θ_j$(或$θ_j^I$)产生两个类分布估计(包括最大类向量和平均类向量)。然后将两个三维类向量相加得到最终的CS度向量，输出数值最大的类，如图1所示。</p>
<h3 id="3-6-Algorithm-Of-S2CL-And-S2CL-alpha"><a href="#3-6-Algorithm-Of-S2CL-And-S2CL-alpha" class="headerlink" title="3.6 Algorithm Of $S2CL$ And ${S2CL}^{\alpha}$"></a>3.6 Algorithm Of $S2CL$ And ${S2CL}^{\alpha}$</h3><img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201101152715584.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201101152715584.png" srcset="/img/loading.gif" alt></p>
<p>step3: 生成初始的概念空间。</p>
<p>step4-8: 概念识别和概念认知过程。</p>
<p>step9-12: 最终的预测。</p>
<p>如果预测值$\hat{k}$与真实标签一致，则S2CL算法是正确的。</p>
<p>数据集T上的精度为: $acc = \frac{N}{|T|}$，$N$表示正确预测的数目。</p>
<p>S2CL算法1的例子</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201103205342992.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201103205342992.png" srcset="/img/loading.gif" alt></p>
<p>K = 1, ${\alpha}_r = 0.5$</p>
<p>则概念分类流程如下:</p>
<ol>
<li>初始概念空间$G_{\mathcal{F_0 H_0}}$和$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}$.</li>
</ol>
<p>条件概念空间$G_{\mathcal{F_0 H_0}}^{0.5, 1} = \{ (1, adgjmp), (2, bdgjmp), (12, djmp) \}, \qquad G_{\mathcal{F_0 H_0}}^{0.5, 2} = \{ (3, afijoq), (4, cehkmp) \}$. </p>
<p>决策概念空间$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 1} = \{ (12, d_1) \}, \qquad G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 2} = \{ (34, d_2) \}$</p>
<p>由于${\alpha}_r = 0.5$,则条件概念空间$G_{\mathcal{F_0 H_0}}$和决策概念空间$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}$可写为$G_{\mathcal{F_0 H_0}}^{0.5}$和$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5}$</p>
<p>而条件概念空间$G_{\mathcal{F_0 H_0}}^{0.5} = \{ G_{\mathcal{F_0 H_0}}^{0.5, 1}, G_{\mathcal{F_0 H_0}}^{0.5, 2} \}$,决策概念空间$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5} = \{ G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 1}, G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 2} \}$.</p>
<ol>
<li>给出第5个实例,则会产生两个概念$(5, begjnp)$和$(5, d_1/d_2)$,记$C_1 = (5, begjnp)$,则$C_1$与$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 1}$之间的概念相似度为</li>
</ol>
<p>$Sim(C_1, G_{\mathcal{F_0 H_0}}^{0.5, 1}) = \{ Sim(C_1, C_j^{0.5}) \}_{j=1}^3 = \{0.333, 0.333, 0.250\}$. </p>
<p>则最大的CS度为</p>
<p>$\hat{\theta}_1 = \max \{ 0.333, 0.333, 0.250\} = 0.333$</p>
<p>$\overline{\theta}_1 = avg \{ 0.333, 0.333, 0.250\} = 0.305$</p>
<p>记$C_j^{0.5, 2} = \{ (3, afijoq), (4, cehkmp) \}$,则</p>
<p>$Sim(C_1, G_{\mathcal{F_0 H_0}}^{0.5, 2}) = \{ Sim(C_1, C_j^{0.5, 2}) \}_{j=1}^2 = \{0.091, 0.200 \}$.</p>
<p>$\hat{\theta}_2 = \max \{ 0.091, 0.200 \} = 0.200$</p>
<p>$\overline{\theta}_2 = avg \{ 0.091, 0.200 \} = 0.145$</p>
<p>则$(\hat{\theta}_1, \hat{\theta}_2)^{\top} = (0.333, 0.200)^{\top},\ \qquad (\overline{\theta}_1, \overline{\theta}_2)^{\top} = (0.305, 0.145)$</p>
<p>则可将第5个实例归类到类别1,即产生概念$(5, d_1)$.</p>
<ol>
<li>更新概念空间,条件概念空间写为$G_{\mathcal{F_0 H_0}}^{0.5}$和决策概念空间$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5}$,则</li>
</ol>
<p>条件概念空间$G_{\mathcal{F_0 H_0}}^{0.5, 1} = \{ (1, adgjmp), (2, bdgjmp), (12, djmp), (5, begjnp), (15, gjp), (25, bjp) \}, \qquad G_{\mathcal{F_0 H_0}}^{0.5, 2} = \{ (3, afijoq), (4, cehkmp) \}$</p>
<p>决策概念空间$G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 1} = \{ (125, d_1) \}, \qquad G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 2} = \{ (34, d_2) \}$</p>
<p>则,最终的概念空间,条件概念空间$G_{\mathcal{F_6 H_6}}^{0.5} = \{ G_{\mathcal{F_0 H_0}}^{0.5, 1}, G_{\mathcal{F_0 H_0}}^{0.5, 2} \}$,决策概念空间$G_{\mathcal{\widetilde{F_6} \widetilde{H_6}}}^{0.5} = \{ G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 1}, G_{\mathcal{\widetilde{F_0} \widetilde{H_0}}}^{0.5, 2} \}$.</p>
<ol>
<li>对于剩余的测试实例6-11,</li>
</ol>
<p>对于测试实例6,产生概念$(6, aegjnq)$</p>
<p>则 $\hat{k} = argmax _{k\in \mathcal{Y}}{\frac{|N_{k}^{\alpha_r}(C_j)|}{K}} $  </p>
<ol>
<li>产生概念</li>
</ol>
<p>同时易于通过使用==概念结构相似度替代算法1的step 6==得到算法${S2CL}^{\alpha}$</p>
<p>S2CL算法的时间复杂度主要由两部分组成：初始概念空间的构建和具有概念结构信息的概念认知过程。</p>
<p>设构造一个概念、计算CS度和更新概念空间的复杂度分别为$O(t_1), O(t_2), O(t_3)$。</p>
<p>则，step 3的时间复杂度为$O(t1|S_L|(|M|+|D|))$，通过概念识别完成概念认知过程的的复杂度为$O(|S_U|(t1+t2+t3))$。</p>
<p>注意，因为所提出的方法是逐个输入对象来更新，所以CCL是一个增量学习过程。因此S2CL也可以看作是动态环境下的一种SSL增量方法。</p>
<p>为了简便，从$S_U$中随机选择实例$E$和$C$分别作为增量学习步骤和每个增量学习步骤的实例。</p>
<p>因此，增量学习算法2的时间复杂度为$O(E|C|(t_1+t_2+t_3)+|T|)$。算法1和算法2的显著区别在于，算法2将在每个增量学习步骤中进行预测过程，这比算法1更耗时。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201101162323691.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201101162323691.png" srcset="/img/loading.gif" alt></p>
<h2 id="4-EXPERIMENTAL-RESULTS"><a href="#4-EXPERIMENTAL-RESULTS" class="headerlink" title="4 EXPERIMENTAL RESULTS"></a>4 EXPERIMENTAL RESULTS</h2><h3 id="4-1-Experimental-Setting"><a href="#4-1-Experimental-Setting" class="headerlink" title="4.1 Experimental Setting"></a>4.1 Experimental Setting</h3><p>将我们提出的两个算法$S2CL$和${S2CL}^{\alpha}$与各种流行的学习算法进行了比较，共有3类</p>
<p>对于概念分类：</p>
<ol>
<li>标准的有监督学习算法：SVM with the Gaussian kernel function，K-Nearest Neighbor(KNN)，Naive Bayes(NB)。</li>
<li>流行的半监督学习算法：semi-supervised SVM self-training(SVM-self)，Label Propagation(LP)，Label Spreading(LS)，以及最先进的SSL方法即TriTraining [6]， CoForest [59] and CoBC[60]。</li>
</ol>
<p>对于增量概念学习：我们将SVM-self，LP， LS,，增量SVM(ISVM)和增量SGD(ISGD)与所提出的S2CL进行的实验比较。</p>
<p>实验设备：Intel Core i5-2400 @3.10GHz CPU and 4GB main memory，我们算法用Java实现。其他算法直接从Sklearn<i><a href="https://scikit-learn.org/stable/" target="_blank" rel="noopener">https://scikit-learn.org/stable/</a></i>或KEEL<i><a href="https://sci2s.ugr.es/keel/download.php" target="_blank" rel="noopener">https://sci2s.ugr.es/keel/download.php</a></i>软件调用。</p>
<p>同时，在我们实验中采用了SVM-Self的高斯核和ISVM的线性核。</p>
<p>每种学习方法的参数设置：</p>
<ol>
<li>高斯核的参数$C$和$\gamma$在网格$[2^{-8}, 2^{-7}, \cdots, 2^8]$搜索。</li>
<li>对于LP和LS，根据不同的数据集调整最大迭代次数，以保证尽可能快的收敛。</li>
<li>对于TriTraining，实验中使用了3个C4.5分类器，CoForest的分类器数量和阈值分别为6个和0.75。</li>
<li>CoBC的参数主要包括3部分：<ol>
<li>committee members: 3。</li>
<li>ensemble learning: bagging。</li>
<li>base learner: C4.5。</li>
</ol>
</li>
<li>我们方法的参数$K\in \{1, 2, \cdots, 10\}$，${\alpha}_r\in \{ 0.0, 0.1, \cdots, 1.0 \}$。</li>
<li>另外，在Sklearning和KEEL软件工具中默认使用其他参数。</li>
</ol>
<h3 id="4-2-Dataset-Setting"><a href="#4-2-Dataset-Setting" class="headerlink" title="4.2 Dataset Setting"></a>4.2 Dataset Setting</h3><p>17个UCI<i><a href="https://archive.ics.uci.edu/ml/datasets.html" target="_blank" rel="noopener">https://archive.ics.uci.edu/ml/datasets.html</a></i>数据集。其中前15个用于概念分类，后2个用于增量学习。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028082844499.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028082844499.png" srcset="/img/loading.gif" alt></p>
<p>对于每个数据集，从源数据集中随机选择$\frac{2}{3}$的实例作为训练数据，剩余的用于测试。</p>
<p>注意，训练集数据既有带标签的数据又有不带标签的数据。</p>
<p>带标签的实例是从原始数据集中随机抽样的，而未标签的实例是通过忽略它们的标签信息从那些未使用的实例中选择出来的。</p>
<p>同时，为了公平的比较，所有的实验都重复了20次，并给出了平均准确度和标准差。</p>
<h3 id="4-3-Concept-Classification"><a href="#4-3-Concept-Classification" class="headerlink" title="4.3 Concept Classification"></a>4.3 Concept Classification</h3><p>从Table 1可以看出，数据集实例大小范围在101~24057之间。这些领域包括</p>
<p>生活(life)：Zoo，Iris，Breast Cancer,，Haberman， WDBC，Thyroid Disease， and Mushroom。</p>
<p>物理(physical): Glass，Ionosphere。</p>
<p>社会(social): Hayes-Roth，Voting Records。</p>
<p>经济(financial): German Credit。</p>
<p>“/“表示对源数据集不做处理，”Discretization”表示用Fayyad和Irani’s MDL方法将数值属性进行离散化。</p>
<p>我们评估了拟议的S2CL在增量学习方面的有效性。最后，我们还在MNIST1数据集上演示了S2CL的效率，MNIST1数据集是一种流行的图像数据集。</p>
<p>$acc = \frac{N}{|T|}$</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028083223143.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028083223143.png" srcset="/img/loading.gif" alt></p>
<p>图2显示了平均排名和临界差异图(CD)(即两种方法的排名在95%的置信度下有显著差异)[63]。从图2中我们可以观察到，S2CL在标签比从0.05到0.15时达到了最好的排名，并且在5%和10%的标签实例中显著高于其他方法。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028083333517.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201028083333517.png" srcset="/img/loading.gif" alt></p>
<h3 id="4-4-Incremental-Learning"><a href="#4-4-Incremental-Learning" class="headerlink" title="4.4 Incremental Learning"></a>4.4 Incremental Learning</h3><p>Algorithm 1 和 2 可以很自然地增量学习。采用了两个数据集HTRU2和Connect-4。</p>
<p>HTRU2：包含由RFI/noise生成的16259个虚假示例，以及High Time Resolution Universe(HTRU) survey 调查搜集的1639示例。</p>
<p>Connect-4：67557个实例组成，每个实例具有42个属性。</p>
<p>相同的预处理技术见表1最后两行。</p>
<p>设E是学习步骤，C是每个学习步骤块的大小。从Fig 3 和 4可知，我们提出的S2CL算法与其他的算法相比具有更高的精确度和更低的低标准差。</p>
<p>因为它们无法在未标记的实例上实现增量学习，所以本节使用了ISVM和ISGD的静态结果。</p>
<p>因此，在图3和图4中，ISVM和ISGD的图形在不同的学习步骤下没有表现出明显的趋势。同时，图5还描述了C=500和第6个学习步骤时这两个数据集的平均误分类率。通过图5可以看到，所提出的S2CL在这些选择的数据集上比其他算法获得更低的误分类率。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170712001.png" srcset="/img/loading.gif" class>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170736591.png" srcset="/img/loading.gif" class>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170843395.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170712001.png" srcset="/img/loading.gif" alt></p>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170736591.png" srcset="/img/loading.gif" alt></p>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170843395.png" srcset="/img/loading.gif" alt></p>
<h3 id="4-5-Experiment-on-the-MINST-Dataset"><a href="#4-5-Experiment-on-the-MINST-Dataset" class="headerlink" title="4.5 Experiment on the MINST Dataset"></a>4.5 Experiment on the MINST Dataset</h3><p>本节，我们将在MINST数据集上进一步评估算法S2CL for SSL的效果。</p>
<p>这个数据集包含60000个训练实例和10000个测试实例，其中每个实例都是手写的0~9数字，尺寸为28$\times$28px。</p>
<p>同时，我们从训练数据中随机选取50、100和200个有标签的样本，其余的训练样本通过忽略它们的标签被认为是无标签的数据。</p>
<p>同时，将S2CL的参数K和${\alpha}_r$分别设置为1和0.5，将算法S2CL与两种半监督单分类器方法即SVM-self(RBFKernel)和SETRED[64]，和半监督的多分类器即TriTraining，CoForest和CoBC。</p>
<p>对于SETRED，我们采用了KEEL软件中的默认参数，其他方法的调整与4.1节类似。</p>
<p>此外，所有的实验也用不同的标签样本(即50、100和200个标签样本)重复了20次，平均性能如表3所示。从表3可以看出，从总体上看，所提出的S2CL具有比其他方法更好或更具竞争力的泛化性能。</p>
<img src="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170549746.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/image-20201102170549746.png" srcset="/img/loading.gif" alt></p>
<h2 id="5-DISCUSSION-AND-CONCLUSION"><a href="#5-DISCUSSION-AND-CONCLUSION" class="headerlink" title="5 DISCUSSION AND CONCLUSION"></a>5 DISCUSSION AND CONCLUSION</h2><p>实验结果表明， </p>
<ol>
<li>分类结果(包括静态分类和增量学习)表明基于概念层次的概念聚类可以提高模型(S2CL)的性能。</li>
<li>与离线初始构建概念格相比，基于GrC的模型也可以获得极好的泛化性能。</li>
<li>关于概念相似度的参数K和${\alpha}_r$对于一个模型来说很重要。</li>
</ol>
<p>实际上，对于增量学习的SSL，经典的SSL仍然面临2个挑战：</p>
<ol>
<li>如何重新设计经典的SSL方法。</li>
<li>在增量的过程中如何利用未标记的实例。</li>
</ol>
<p>同时，我们也注意到概念结构信息在人类知识组织中起着非常重要的作用。为此，我们利用概念相似度，提出了一种基于正则决策形式背景的$S2CL$(或${S2CL}^α$) for SSL理论框架来应对这些挑战，并给出了相应的算法。</p>
<p>与经典的SSL算法相比，我们的方法基于一种新的CCL理论而不是标准的机器学习理论来实现增量SSL。</p>
<p>S2CL有很多好的特性：</p>
<ol>
<li>可以通过概念相似度来最大限度地利用概念的结构信息来提高概念分类的性能，还可以通过模仿人类的认知过程来完成动态过程，从而避免了昂贵的计算。</li>
<li>在不同数据集上的实验结果表明，S2CL可以通过概念认知过程获得更好的SSL性能。</li>
</ol>
<p>但是，我们必须认识到，S2CL不能直接处理具有连续值的数据集，这会导致两个关键问题:</p>
<ol>
<li>需要对数值属性进行离散化。</li>
<li>不同的离散化技术会产生不同的分类性能。</li>
</ol>
<p>同时，值得注意的是，我们的另一个目标是试图从人类认知过程的角度探索一种新的SSL学习方法。</p>
<p>此外，关于S2CL的许多有趣问题的深入研究仍值得进一步研究。</p>
<ol>
<li>例如要直接处理具有连续值和不确定性的数据集，我们需要探索模糊数据[56]和固有不确定性[65]。</li>
<li>为了在不同的信息系统中实现概念泛化能力，我们必须研究多源数据集中的S2CL[66]。</li>
<li>受大数据挖掘中知识获取的启发[67]、[68]，知识抽取的方法也可以集成到S2CL中，从海量数据中学习有用的信息，做出智能决策[69]。</li>
<li>此外，为了进一步提高SSL的性能，可以从虚拟样本生成的角度将生成器方法[70]整合到当前的SSL方法中，并且还可以在算法设计方面将Co-training[71]等集成策略整合到当前的SSL方法中。</li>
<li>更重要的是，作为一项有意义的未来研究工作，分析概念聚类稳定性对分类结果的影响仍然是必要的，这也可能成为从提高分类性能的角度研究概念聚类稳定性的深入思考。文献[49]中的工作可能会为这一研究方向的开始提供一个很好的参考。</li>
</ol>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AE%BA%E6%96%87/%E6%A6%82%E5%BF%B5%E8%AE%A4%E7%9F%A5%E5%AD%A6%E4%B9%A0/">概念认知学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0/">增量学习</a>
                    
                      <a class="hover-with-bg" href="/tags/%E6%A6%82%E5%BF%B5%E8%AE%A4%E7%9F%A5%E5%AD%A6%E4%B9%A0/">概念认知学习</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">半监督学习</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/09/18/2020%E5%8D%8E%E4%B8%BA%E6%9D%AFD%E9%A2%98--%E6%97%A0%E4%BA%BA%E6%9C%BA%E9%9B%86%E7%BE%A4%E5%8D%8F%E5%90%8C%E5%AF%B9%E6%8A%97/">
                        <span class="hidden-mobile">2020华为杯D题--无人机集群协同对抗</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "RcI3ePX6qkbdKOX0xjPq8Xy3-gzGzoHsz",
          app_key: "suQG3XDbcx2bpMJLeuKCcqS7",
          placeholder: "由于作者水平有限，加上时间仓促，文中难免存在不足之处，敬请读者批评指正。",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: false,
          serverURLs: "https://rci3epx6.lc-cn-n1-shared.com",
        });
      });
    }
    createObserver(loadValine, 'vcomments');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <!--
 * @Author: your name
 * @Date: 2020-06-04 05:16:36
 * @LastEditTime: 2020-07-04 16:26:58
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: \blog\themes\fluid\layout\_partial\footer.ejs
--> 
<footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://github.com/SuperficialJ/peerless.github.io." target="_blank" rel="nofollow noopener"><span>peerless</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    <!--
 * @Author: your name
 * @Date: 2020-06-28 18:23:11
 * @LastEditTime: 2020-07-04 16:28:28
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: \peer-less.github.io\themes\fluid\layout\_partial\statistics.ejs
--> 

  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: inline-block">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: inline-block">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


    

    
  </div>

  <p id="hitokoto" align='center'>:D 获取中...</p>
  <script>
    fetch('https://v1.hitokoto.cn')
      .then(response => response.json())
      .then(data => {
        const hitokoto = document.getElementById('hitokoto')
        hitokoto.innerText = data.hitokoto
        })
        .catch(console.error)
  </script>

  <div align='center'>
    <span id="timeDate">载入天数...</span>
    <span id="times">载入时分秒...</span>
    <script>
    var now = new Date();
    function createtime(){
        var grt= new Date("06/26/2020 22:53:55");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24;
        dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
        hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){
            hnum = "0" + hnum;
        }
        minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes);
        if(String(mnum).length ==1 ){
                  mnum = "0" + mnum;
        }
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds);
        if(String(snum).length ==1 ){
                  snum = "0" + snum;
        }
        document.getElementById("timeDate").innerHTML = "本站安全运行&nbsp"+dnum+"&nbsp天";
        document.getElementById("times").innerHTML = hnum + "&nbsp小时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
    }
    setInterval("createtime()",250);
    </script>
  </div>

  
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "2020-IEEE TKDE-Semi-supervised Concept Learning by Concept-cognitive Learning and Concept Space&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  



  
  
    <script type="text/javascript">
      //定义获取词语下标
      var a_idx = 0;
      jQuery(document).ready(function ($) {
        //点击body时触发事件
        $("body").click(function (e) {
          //需要显示的词语
          var a = new Array("富强", "民主", "文明", "和谐", "自由", "平等", "公正", "法治", "爱国", "敬业", "诚信", "友善");
          //设置词语给span标签
          var $i = $("<span/>").text(a[a_idx]);
          //下标等于原来下标+1  余 词语总数
          a_idx = (a_idx + 1) % a.length;
          //获取鼠标指针的位置，分别相对于文档的左和右边缘。
          //获取x和y的指针坐标
          var x = e.pageX, y = e.pageY;
          //在鼠标的指针的位置给$i定义的span标签添加css样式
          $i.css({
            "z-index": 999,
            "top": y - 20,
            "left": x,
            "position": "absolute",
            "font-weight": "bold",
            "color": rand_color()
          });
          // 随机颜色
          function rand_color() {
            return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
          }
          //在body添加这个标签
          $("body").append($i);
          //animate() 方法执行 CSS 属性集的自定义动画。
          //该方法通过CSS样式将元素从一个状态改变为另一个状态。CSS属性值是逐渐改变的，这样就可以创建动画效果。
          //详情请看http://www.w3school.com.cn/jquery/effect_animate.asp
          $i.animate({
            //将原来的位置向上移动180
            "top": y - 180,
            "opacity": 0
            //1500动画的速度
          }, 1500, function () {
            //时间到了自动删除
            $i.remove();
          });
        });
      })
      ;
    </script>
  











  

  

  

  

  

  





</body>
</html>
