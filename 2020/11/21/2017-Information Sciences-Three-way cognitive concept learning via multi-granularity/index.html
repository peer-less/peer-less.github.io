<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="个人博客，记录成长的点滴。">
  <meta name="author" content="peerless">
  <meta name="keywords" content="">
  <title>2017-Information Sciences-Three-way cognitive concept learning via multi-granularity - peerless</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>peerless</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-11-21 21:32">
      2020年11月21日 晚上
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      10.6k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      130
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1 id="Three-way-cognitive-concept-learning-via-multi-granularity"><a href="#Three-way-cognitive-concept-learning-via-multi-granularity" class="headerlink" title="Three-way cognitive concept learning via multi-granularity"></a>Three-way cognitive concept learning via multi-granularity</h1><div class="note note-primary">
            <p>三支粒概念、概念认知学习、多粒度</p>
          </div> 
<a id="more"></a>
<!-- <p class='note note-info'>论文、属性探索</p> -->
<h2 id="论文基本信息"><a href="#论文基本信息" class="headerlink" title="论文基本信息"></a>论文基本信息</h2><pre><code>           1. 作者：Jinhai Li, Chenchen Huang, Jianjun Qi, Yuhua Qian, Wenqi Liu。
</code></pre><ol>
<li>期刊：Information Sciences 。</li>
</ol>
<ul>
<li>SCI： 1区。    </li>
<li>CCF： B类。        </li>
<li>IF: 5.91。</li>
</ul>
<p>​            3. 时间：2017。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              </p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ol>
<li><p>三支决策理论的核心策略是将一个决策问题看作一个三分类问题(即接受、拒绝和不承诺)。</p>
</li>
<li><p>最近，该理论被引入到形式概念分析中，用于挖掘形式背景下的三支概念以支持三支决策。</p>
</li>
<li><p>也就是说，在概念的外延或内涵的设计中融入了三元分类的思想，从而实现了三分类。</p>
</li>
<li><p>然而，现有的三支概念研究方法是建构性的，也就是说，三支概念是通过预先定义的概念形成算子而形成的。</p>
</li>
<li><p>为了从认知的角度揭示三支概念决策的本质特征，有必要在一般概念形成算子的框架下对三支概念进行重新思考。</p>
</li>
<li><p>换句话说，描述三向概念需要公理方法。</p>
<p> 受此问题的驱使，本研究主要从认知的角度对多粒度的三支概念学习进行了研究。具体地说，</p>
<ol>
<li>我们首先提出了一种用多粒度来描述三支概念的公理方法。</li>
<li>我们设计了一个三支概念认知计算系统来发现复合的三支认知概念。</li>
<li>我们使用集合近似的思想来模拟从给定线索学习三向认知概念的认知过程。</li>
<li>通过数值实验对所提出的学习方法的性能进行了评估。</li>
</ol>
</li>
</ol>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>==三支决策==是解决决策问题的重要途径之一。他们的关键策略是把一个决策问题看作一个由接受、拒绝和不承诺构成的三分类问题[60]。</p>
<p>到目前为止，从多个方面为三支决策理论的发展作出了实质性贡献。例如，</p>
<ol>
<li>姚[58]利用经典粗糙集模型和决策理论粗糙集模型讨论了三支决策规则，并从误分类代价的角度阐述了三支决策的优越性[59]。</li>
<li>杨和姚[53]利用决策理论粗糙集对多智能体三支决策进行建模。</li>
<li>邓和姚[6]利用模糊隶属函数中的两个参数提出了模糊集的三支逼近。</li>
<li>胡[9]建立了三支决策的公理方法及其相应的空间。</li>
<li>为了解决直觉模糊环境下的单周期和多周期决策问题，梁和刘[19]建立了三支决策模型。</li>
<li>刘等人[51]从利润最大化的投资决策问题出发，推导出三支决策。</li>
<li>此外，三向决策已被应用于垃圾邮件过滤[12]、对成本敏感的人脸识别[18]、推荐系统设计[65]、群集分析[67]等[68]。</li>
</ol>
<p>==认知计算==是以人脑为模型的计算机系统[42]。它的主要目的是用计算机模拟人类的思维过程(如感知、注意和学习)。</p>
<p>认知学习是用来模拟认知过程的功能，比如思考和记忆的操作。一般而言，认知学习可以看作是实现认知计算的一种数学工具。</p>
<p>此外，认知计算和认知学习在发展过程中都吸收了心理学、信息论和数学的许多新方法[41]。</p>
<p>概念通常由其外延和内涵部分构成，是哲学中人类认知的基本单位[41]，通常用于识别现实世界的具体实体或对感知世界的抽象主体进行建模[42]。</p>
<p>到目前为止，人们已经提出了抽象概念[41]、Wille概念[46]、面向属性概念[7]、面向对象概念[55，56]、AFS概念[43]和近似概念[15]等多种概念来满足认知知识发现的不同需求。这些定义明确的概念可以根据其内涵的特点相互区分，其形式可以是合取的、析取的或混合的。</p>
<p>最近，齐等人将三支决策理论与形式概念分析相结合。[31，32]提出了三支概念的概念，以支持形式背景下的三支决策，其主要策略是将==三元分类==的思想融入到概念的外延或内涵的设计中。</p>
<p>然而，现有的三支概念研究方法都是建构性的，即三向概念是通过预先引入一定的概念形成算子而产生的。换言之，研究者可能会用不同的属性来定义不同的三元概念，这就产生了一个问题，即哪些属性是表征三支概念的内在属性。这个问题的答案很重要，因为它们可以帮助理解三支概念的最基本的决策机制。</p>
<p>因此，在做出决策时，公理方法需要超越表象，==寻找三支概念的本质==。本文的主题就是解决这一问题。</p>
<p>概念学习是通过一定的方法从给定的线索中学习未知概念，如概念代数系统[41]、查询[1]、认知系统[66]、云模型[44]、集合近似[16]、迭代[35]等。</p>
<p>根据姚氏的信息处理三角[57]，概念学习可以从抽象层次、大脑层次和机器层次三个方面进行研究。更具体地说，抽象层次的概念学习需要从哲学、数学和逻辑三个层面进行分析。例如，</p>
<p>概念的形式化通常参考哲学的原则[14]，一般概念形成算子的建立需要公理方法[23]，逻辑有利于连贯认知系统的设计。</p>
<p>大脑层面的概念学习将在心理学和神经科学中进行讨论。例如，</p>
<p>在探索公理方法时，必须适当考虑认知心理学中关于感知、注意力和思维的原则[14，16]。</p>
<p>此外，神经元之间的双向回忆可以帮助定义概念的外延部分和内涵部分之间的合理映射[2]。</p>
<p>机器层面的概念学习是计算机科学和信息科学的研究内容。</p>
<p>由于发展了许多有效的方法[1，14，35，49，50]来从给定的线索中学习概念，这方面的研究越来越受到人们的关注。</p>
<p>事实上，抽象的概念学习、大脑和机器三个层面是相对独立的，彼此之间有着密切的联系。这就是说，一方面，它们可以各自独立研究。另一方面，其中任何一个的结果都有利于更好地理解另外两个因素。我们认为，只有在统一的框架下考虑这三个方面，才能对概念学习有一个全面的理解。目前的工作是从抽象和机器两个层面对三支概念学习的研究产生了浓厚的兴趣。</p>
<p>==粒计算==[63]已经成为构建、描述和处理信息颗粒的统一且连贯的平台。目前，已经为信息颗粒设计了各种模型[3，4，26-30，36，45，54]。</p>
<p>一般说来，由(相似性、近似性、功能性等)引起的信息颗粒的收集。关系可以形成单一粒度的话语宇宙。然而，在许多实际应用中，解决问题也需要多个粒度(通常称为多粒度)。</p>
<p>例如，在一个有多个专家的分类问题中，不同的专家对样本分类有不同的看法是很常见的情况。在这种情况下，每个专家可以根据他或她的个人喜好给出一个独立的样品粒度。然后，将这些专家的多个粒度进行有效组合，即可得到最终的分类结果。</p>
<p>事实上，多粒度观在粗糙集理论中已经得到了广泛的应用。</p>
<p>例如，考虑到在多尺度数据集中会产生多个粒度[47]，Wu和Leung[48]研究了如何选择最优的粒度来优化粒度信息。最优的粒度选择也从局部方法的角度进行了研究[40]。梁等人。[20]采用多粒度视图，加快了近似约简的搜索速度。在多粒度的基础上，钱等人提出了一种新的方法。[33，34]提出了两种新的用于信息融合的粗糙集模型(悲观多粒粗糙集和乐观多粒粗糙集)，并设计了基于这两种多粒粗糙集的分类器。</p>
<p>此外，在基于邻域的、容差的、覆盖的和模糊的粗糙集模型[1，21，22]中进一步融合了多粒度信息，用于复杂信息融合。此外，还比较了基于多粒度的经典粗糙集模型和广义粗糙集模型，并将其与形式概念分析、代价敏感分类等理论联系起来[17，39，52，62]。</p>
<p>在本文中，我们将使用多粒度来讨论三支概念学习。</p>
<p>==认知观点==在概念学习[2，14，16，49，50，57，66]的研究中被广泛采用，因为它在模拟大脑的思维、学习和推理等智力行为方面有着广泛的应用背景。</p>
<p>因此，本文也将这一思想融入到三支概念学习中。综上所述，基于多粒度的三支认知概念学习值得研究，这也是我们目前研究的主要问题。具体地说，</p>
<ol>
<li><p>我们提出了一种基于多粒度的公理方法来描述三支概念。</p>
</li>
<li><p>建立了一个发现复合三支认知概念的三支概念认知计算系统，并模拟了从给定线索学习三向概念的认知过程。</p>
</li>
<li><p>此外，还进行了一些数值实验来评估所提出的学习方法的性能。</p>
</li>
</ol>
<p>本文的主要贡献在于从认知的角度揭示了三支概念在解决决策问题中的本质思想，即阐明三支概念的哪些属性是内在的。</p>
<p>本文件的其余部分组织如下。</p>
<ol>
<li><p>第二节分析了基于多粒度和三支决策原则的三支概念形成的认知机制。提出了三支概念认知算子、三支认知概念和三支粒概念。文中还讨论了一些重要性质。</p>
</li>
<li><p>第三节设计了一个三支概念认知计算系统，它实际上是一个动态更新三支粒概念的过程。</p>
</li>
<li><p>第四节利用集合近似的思想来模拟从给定线索学习三支概念认知的认知过程。</p>
</li>
<li><p>第五节进行了一些数值实验，以评估所提出的学习方法的性能。</p>
</li>
<li><p>最后，对全文进行了简要的总结，并对进一步的研究进行了展望。</p>
</li>
</ol>
<h2 id="2-Cognitive-mechanism-of-forming-three-way-concepts"><a href="#2-Cognitive-mechanism-of-forming-three-way-concepts" class="headerlink" title="2. Cognitive mechanism of forming three-way concepts"></a>2. Cognitive mechanism of forming three-way concepts</h2><p>在这一部分中，我们分析了基于多粒度和三支决策原则的三支概念形成的认知机制。在本文中，我们用U表示非空对象集，即对象集，用A表示属性集。</p>
<h3 id="2-1-Basic-notions"><a href="#2-1-Basic-notions" class="headerlink" title="2.1 Basic notions"></a>2.1 Basic notions</h3><p>首先介绍了三支决策、三支商集及其幂集合的概念。根据粗糙集理论[25]中的符号，我们仍然将诱导三支决策(即接受、拒绝和不承诺[60])的集合称为正、负和边界区域[5，10，64，69]。此外，在随后的讨论中，正区域、负区域和边界区域与它们各自的三支判定没有区别。</p>
<p>对象集: $x\in U$，属性集: $A_i \subseteq A$，评价函数：$f_{A_I}(x)$是与$A_i$相关的评价函数。</p>
<p>两个参数：$\beta &lt; \alpha$。</p>
<p>则</p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/SMPX3X8%60DU%25VW8OHHVYK7O.png" srcset="/img/loading.gif" alt="img"></p>
<p>此外，我们说$X_i、Y_i$和$Z_i$是由$A_i$在$α$和$β$的帮助下诱导的三支决策。事实上，在粒计算中，三支决策$X_i、Y_i$和$Z_i$通过消除空集形成了$U$的粒度。请注意，这些三支决策满足$X_i \cup Y_i \cup Z_i = U$，因此，描述其中任意两个的三支决策就足够了。在此之后，我们选择$(X_i，Y_i)$来表示不引起混淆的三支决策。</p>
<p>设$S$是一个指标集。设$(X_i，Y_i)(i∈S)$是由$A$的多个子集$A_i(i∈S)$诱导的一系列三支决策。然后，对于每个$i \in S$，三支决策$(X_i，Y_i)$可以通过消除空集来形成$U$的粒度。因此，$(X_i，Y_i)(i∈S)$可以看作是$U$的多粒度的结果。</p>
<p>此外，如果多个子集$A_i(i∈S)$构成$A$的一个划分，则$Q(A)=\{A_i|i∈S\}$称为$A$的一个三支商集。为方便起见，我们用$2^{Q(A)}$表示$Q(A)$的幂集合。这里，每一个$B∈2^{Q(A)}$都可以看作是一组共同诱导三向决策的知识。</p>
<h3 id="2-2-Three-way-cognitive-operators-induced-by-multi-granularity-and-three-way-decision-making-principles"><a href="#2-2-Three-way-cognitive-operators-induced-by-multi-granularity-and-three-way-decision-making-principles" class="headerlink" title="2.2 Three-way cognitive operators induced by multi-granularity and three-way-decision-making principles"></a>2.2 Three-way cognitive operators induced by multi-granularity and three-way-decision-making principles</h3><p>对于$U$上任意两个三支决策$(X_i, Y_i)$和$(X_j, Y_j)$，如果有$X_i \subseteq X_j$和$Y_i \subseteq Y_j$，那么$(X_j, Y_j)$比$(X_i, Y_i)$更有效，记作$(X_i, Y_i) \preccurlyeq (X_j, Y_j)$，并且，如果$(X_i, Y_i) \preccurlyeq (X_j, Y_j)$，那么就说$(X_i, Y_i) $关于$(X_j, Y_j)$是决策一致的。</p>
<p> 由$U$的多粒度诱导的三支决策集合被表示为$T(U)$。此外，$T(U)$中的交集和并集分别定义为                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </p>
<script type="math/tex; mode=display">
\begin{aligned}
(X_i, Y_i) \cap (X_j, Y_j) = (X_i \cap X_j, Y_i \cap Y_i) \newline
(X_i, Y_i) \cup (X_j, Y_j) = (X_i \cup X_j, Y_i \cup Y_i)
\end{aligned}</script><p>现在，我们讨论$H：2^{Q(A)}→T(U)$和$L：T(U)→2^{Q(A)}$映射在形成三支概念时需要遵循什么？</p>
<p>Definition 1.</p>
<p>三支决策原则一：根据序贯或动态三向决策[9，18，61]，我们用来诱导三支决策的知识越多，诱导出的三支决策越有效。</p>
<script type="math/tex; mode=display">（1） B_i \subseteq B_j \Rightarrow H(B_i) \preccurlyeq H(B_j) $$，即新型冠状病毒患者的已获得的症状越多，越能做出合理的决策。

三支决策原则二：整个集团的三支决策不如或等于其子集团的三支决策的总和。

$$（2） H(B_i \cup B_j) \preccurlyeq H(B_i) \cup H(B_j) $$，将患者隔离观察比集中观察更容易对患者做出合理的决策。

三支决策原则三：知识是否被选择取决于其诱导的三支决策相对于目标三支决策$(X，Y)$的决策一致性程度。

$$（3） L(X, Y) = \{ A_i \in Q(A) | H(\{A_i\}) \preccurlyeq (X, Y) \} $$，新患者症状与已获得的症状集合的一致性来对新患者做出合理的决策。                                                     

 请注意， 将$H$和$L$称为三支认知算子的原因如下：

1. $H$和$L$都涉及三支判断，即$H$的共域和$L$的域；

2. $H$和$L$可以共同构成概念，即概念的识别。              

事实上，性质(1)(2)(3)是非常重要的，因为它们可以共同用作刻画三支概念的公理。因此，这些性质可以看作是刻画==三支概念的内在性质==。

Remark 1. 对于三支认知算子$H$和$L$，如果$X$和$Y$同时为空，我们说由非空集$B∈2^{Q(A)}$(即$H(B)=(X，Y)$)诱导的三支决策$(X，Y)$是平凡的。在下文中，假设由任意非空集$B∈2^{Q(A)}$诱导的三支决策不是平凡的。即$X$和$Y$不同时为$\empty$。

Remark 2. 对于由两个非空集$B_i，B_j∈2^{Q(A)}$产生的三支决策$(X_i，Y_i)$和$(X_j，Y_j)$，如果$X_i∩Y_j=∅$和$Y_i∩X_j=∅$，我们说$(X_i，y_i)$和$(X_j，Y_j)$是互不矛盾的。在本文的其余部分中，假设由任意两个非空集$B_i，B_j∈2^{Q(A)}$诱导的三支决策是互不矛盾的。

<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123100858354.png" srcset="/img/loading.gif" class="">

![](2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123100858354.png)

   <img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123101633654.png" srcset="/img/loading.gif" class="">                                                                                                                                            

![image-20201123101633654](2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123101633654.png)

<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123102000892.png" srcset="/img/loading.gif" class="">

![image-20201123102000892](2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123102000892.png)

Proposition 1. 设$H$和$L$是三支认知算子。那么对于任何非空集$B∈2^{Q(A)}$，我们有

$$ (4) \quad H(B) = \bigcup\limits_{A_i \in B} H(A_i) $$，即$H(\{ A_i, A_j \}) = H(A_i) \cup H(A_j)$

Proposition 2. 设$H$和$L$是三支认知算子。对于任意$B∈2^{Q(A)}$和$(X，Y)，(X_i，Y_i)，(X_j，Y_j)∈T(U)$，我们有以下性质：

$$ (5) \quad B\subseteq LH(B)</script><script type="math/tex; mode=display">(6) \quad HL(X,Y) \preccurlyeq (X, Y)</script><script type="math/tex; mode=display">(7) \quad (X_i, Y_i) \preccurlyeq (X_j, Y_j) \Rightarrow L(X_i, Y_i) \subseteq L(X_j, Y_j)</script><p>需要指出的是等式(1)，(5)，(6)，(7)在$2^{Q(A)}$和$T(U)$间形成了保序伽罗瓦连接，这意味着可以联合使用映射$H$和$L$来归纳概念。此外，传统的是反序伽罗瓦连接。即</p>
<p>本文：积累知识越多，对概念认知理解的越透彻。</p>
<p>传统：检索论文时，关键词越多，检索出来的论文越少。</p>
<h3 id="2-3-Three-way-cognitive-concepts-and-three-way-granular-concepts"><a href="#2-3-Three-way-cognitive-concepts-and-three-way-granular-concepts" class="headerlink" title="2.3 Three-way cognitive concepts and three-way granular concepts"></a>2.3 Three-way cognitive concepts and three-way granular concepts</h3><p>在这一小节中，我们提出了三支认知概念的概念，并讨论了三支认知概念的信息粒度。</p>
<p>Definition 2. 设$H$和$L$是三支概念认知算子。对于$B∈2^{Q(A)}$和$(X，Y)∈T(U)$，如果$H(B)=(X，Y)$和$L(X，Y)=B$，我们说$\langle (X，Y)，B \rangle$是认知运算符$H$和$L$下的三支概念(或简单的三支认知概念)。在这种情况下，$(X，Y)$和$B$被称为三支认知概念$\langle (X，Y)，B \rangle$的外延和内涵。此后，所有三支认知概念的集合被表示为$\mathfrak{B}(2^{Q(A)}，T(U)，H，L)$。</p>
<p>三支认知概念不同于三元概念[13]，三元概念包括外延、内涵和方法。原因如下：                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </p>
<ol>
<li>三支认知概念的外延由正域、负域和边界域构成，而三元概念的外延只是对象集的一个子集。</li>
<li>用于诱导基本三支决策的属性集$A_i(i∈S)$是不存在交集的(例如参见表1中的域1-3下的属性集)，而在三元形式背景下的属性集是相同的。也就是说，三支认知概念的外延和内涵之间的关系不同于三元概念。更具体地说，前者认为内涵是一种评价函数，将整个对象集划分为正、负和边界三个区域以生成外延，而后者则强调外延上的每个对象在各种条件下都具有内涵的所有属性。</li>
</ol>
<p>下确界($\bigwedge$)和上确界($\bigvee$)定义为：</p>
<p>$\langle (X_i, Y_i), B_i \rangle \bigwedge \langle (X_j, Y_j), B_j \rangle = \langle HL((X_i, Y_i)\cap(X_j, Y_j)), B_i \cap B_j \rangle $</p>
<p>$\langle (X_i, Y_i), B_i \rangle \bigvee \langle (X_j, Y_j), B_j \rangle = \langle ((X_i, Y_i)\cup(X_j, Y_j)), LH(B_i \cup B_j) \rangle $</p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123153531877.png" srcset="/img/loading.gif" alt="image-20201123153531877"></p>
<p>Definition 3. 设$H$和$L$是三支概念认知算子。则$H^G=\{\{A_i\}→H(A_i)|A_i∈Q(A)\}$称为$H$的信息粒。(4)，信息粒H_G可用于生成映射H。</p>
<p>根据公式$ (4) \quad H(B) = \bigcup\limits_{A_i \in B} H(A_i) $，信息粒$H^G$可用于生成映射$H$。</p>
<p>Proposition 3. 设$H$和$L$是三支概念认知算子。则对任一$B∈2^{Q(A)}$，$\langle H(B)，LH(B) \rangle$是一个三支认知概念。</p>
<p>命题3进一步用于通过取$B={A_i}$来定义三支粒概念的定义，其形式化如下</p>
<p>Definition 4. 设$H$和$L$是三支概念认知算子。那么对于任意的单元集${A_i}∈2^{Q(A)}$，我们说$\langle H(A_i)，LH(A_i) \rangle$是一个三支粒概念。</p>
<p>Proposition 4. 设$H$和$L$是三支概念认知算子。那么对任意$\langle (X，Y)，B \rangle ∈\mathfrak{B}(2^{Q(A)}，T(U)，H，L)$，我们有</p>
<script type="math/tex; mode=display">\langle (X，Y)，B \rangle = \bigvee\limits_{A_i \in B} \langle H(A_i), LH(A_i) \rangle</script><p>命题4指出，任何三支认知概念都可以通过整合三支粒概念来归纳出。因此，在粒计算中，三支粒概念可以看作是$\mathfrak{B} (2^{Q(A)}，T(U)，H，L)$的信息粒。在下文中，我们用$G_{HL}$表示信息粒的集合。即</p>
<script type="math/tex; mode=display">(10) \quad G_{HL} = \{ \langle H(A_i), LH(A_i)  \rangle | A_i \in Q(A) \}</script><img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123163714201.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123163714201.png" srcset="/img/loading.gif" alt="image-20201123163714201"></p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123163852715.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123163852715.png" srcset="/img/loading.gif" alt="image-20201123163852715"></p>
<h2 id="3-Three-way-cognitive-computing-system"><a href="#3-Three-way-cognitive-computing-system" class="headerlink" title="3. Three-way cognitive computing system"></a>3. Three-way cognitive computing system</h2><p>在认知计算中，概念应该被更新，以模拟信息周期性更新时大脑的智能行为。例如，在例子1中，7名审稿人对9份手稿进行了评估。随着时间的推移，一方面，新的手稿会陆续到来。另一方面，那些落入边界区域的需要通过邀请额外的审查员进行评估。在这种情况下，有必要更新三支粒概念，以支持对未提交决定的稿件的进一步决定。</p>
<p>基于上述问题，我们在这一部分提出了一个三支概念认知计算系统，用于随着对象和/或属性的批量增加而更新三支粒概念。在开始讨论这个问题之前，我们先介绍一些符号。</p>
<p>n个属性集：$A_1 \subseteq A_2 \subseteq \cdots \subseteq A_n$，记作$\{ A_t | t\in S = \{1, 2, \cdots, n \} \}$</p>
<p>n个对象集：$U_1 \subseteq U_2 \subseteq \cdots \subseteq U_n$，记作$\{ U_t | t\in S = \{1, 2, \cdots, n \} \}$</p>
<p>$\triangle A_{i-1} = A_i - A_{i-1}$ 和 $\triangle U_{i-1} = U_i - U_{i-1}$</p>
<p>此外，对于任意$i\in S$，记$2^{Q(A_i)}$为三支商集$A_i$的幂集，$T(U_i)$表示$U_i$的三支决策集。</p>
<p>对于任一$A_{i−1s}∈Q(A_{i−1})$，如果存在$A_{it}∈Q(A_i)$使得$A_{i−1s}⊆A_{it}$，则$Q(A_i)$称为$Q(A_{i−1})$的泛化，或者等价地$Q(A_{i−1})$是$Q(A_i)$的例化，其中$i−1，s，i$和$t$是下标索引。我们用$Q(A_{i−1})≤Q(A_i)$表示这种泛化/例化关系。</p>
<p>在现实世界中，这样的关系很容易理解。例如，在示例1中，用于评估落入边界区域的稿件的新的受邀审稿人必须来自域1、域2、域3或新域。</p>
<p>假设</p>
<script type="math/tex; mode=display">H_{i-1}: 2^{Q(A_{i-1})} \rightarrow T(U_{i-1}) \quad  H_{\triangle U_{i-1}}: 2^{Q(A_{i-1})} \rightarrow T(\triangle U_{i-1})</script><img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123194557434.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123194557434.png" srcset="/img/loading.gif" alt="image-20201123194557434"></p>
<p>然后，我们继续分析映射$H_{\triangle U_{i-1}}$。与$H_{i-1}$的情况一样，信息粒$H_{\triangle U_{i-1}}^G$可以确定$H_{\triangle U_{i-1}}$。因此，图2实际上描绘了$H_{\triangle U_{i-1}}$的图，其中每个属性集合$A_{i−1j}(j=1，2，\cdots , n_{i−1})$将$\triangle U_{i-1}$分成三支决策$\triangle X_{i-1}, \triangle Y_{i-1}$和$\triangle Z_{i-1}$。毫无疑问，边界区域$\triangle Z_{i−1j}(j=1，2，\cdots, n_{i−1})$也需要额外的信息来做出决定。</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123202552374.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123202552374.png" srcset="/img/loading.gif" alt="image-20201123202552374"></p>
<p>假设</p>
<script type="math/tex; mode=display">H_{\triangle A_{i-1}}: 2^{Q(A_i)} \rightarrow T(U^*)</script><p>公式中$Q(A_{i−1})≤Q(A_i)$和$U^∗=\bigcup_{j=1}^{n_{i-1}} (Z_{i−1j}∪ \triangle Z_{i−1j})$。边界区域$Z_{i−1j}$和$\triangle Z_{i−1j}$可以分别在图1和图2中找到。换言之，将属性集$ \triangle A_{i-1} $与$A_{i−1}$相结合，以支持对边界区域中的对象的进一步决策。这符合顺序或动态三支决策的思想[9，18，61]。此外，$ H_{\triangle A_{i-1}} $的曲线图如图3所示。在图中，每个属性集合$A_{ij}(j=1，2，\cdots，n_{i−1})$将$U^∗$划分为三支决策$(X_{i-1j}^Z \cup \triangle X_{i-1j}^{\triangle Z}, Y_{i-1j}^Z \cup \triangle Y_{i-1j}^{\triangle Z})$，而每个属性集$A_{ij}(j=n_{i−1}+1，\cdots, n_i)$将$U^∗$划分为三支决策$(X_{ij}，Y_{ij})$。</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123212540208.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123212540208.png" srcset="/img/loading.gif" alt="image-20201123212540208"></p>
<p>最终假设</p>
<script type="math/tex; mode=display">H_i: 2^{Q(A_i)} \rightarrow T(U_i)</script><p>其中信息粒$H_i$定义为</p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123213019242.png" srcset="/img/loading.gif" alt="image-20201123213019242"></p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123213313731.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123213313731.png" srcset="/img/loading.gif" alt="image-20201123213313731"></p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123213633711.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201123213633711.png" srcset="/img/loading.gif" alt="image-20201123213633711"></p>
<p>Definition 5. 通过结合信息$H_{\triangle U_{i-1}}$ 和$H_{\triangle A_{i-1}}$我们称$H_i$和$L_i$是$H_{i−1}$和$L_{i−1}$的扩展的三支概念认知算子。</p>
<p>$F_{H_{i} L_{i}} = (G_{H_{i-1} L_{i-1}}, H_{\triangle U_{i-1}}, H_{\triangle A_{i-1}})$ 为一个三支概念认知计算状态，$G_{H_{i-1} L_{i-1}}$是在$H_{i-1}$和$L_{i-1}$下的三支粒概念。而且三支概念认知计算状态$F = \bigcup_{i=2}^n \{ F_{H_i L_i} \}$称为一个三支概念认知计算系统。</p>
<p>请注意，设计一个三支认知计算系统的目标是在对象和/或属性批量增加时更新三支粒概念。这符合我们的常识，在现实世界中，在信息更新的情况下，概念的更新会逐渐完善，直到保持相对稳定。为了实现这一任务，有必要分析三支粒概念从一个三支认知计算状态到另一个三支·认知计算状态的转换机制。</p>
<p>Proposition 5. 设$F_{H_{i} L_{i}} = (G_{H_{i-1} L_{i-1}}, H_{\triangle U_{i-1}}, H_{\triangle A_{i-1}})$为三支概念认知计算状态，且$Q(A_{i-1}) \le Q(A_i)$。对于任一$A_{it} \in Q(A_i)$，如果存在$A_{i-1s} \in Q(A_{it})$，那么我们有</p>
<script type="math/tex; mode=display">H_i(A_{it}) = H_{i-1}(A_{i-1s}) \cup H_{\triangle U_{i-1}}(A_{i-1s}) \cup H_{\triangle A_{i-1}}(A_{it})</script><p>否则,</p>
<script type="math/tex; mode=display">H_i(A_{it}) = H_{\triangle A_{i-1}}(A_{it})</script><p>Remark 3. 基于定义1的(3)，我们有</p>
<script type="math/tex; mode=display">L_iH_i(A_{it}) = \{ A_{is} \in Q(A_i) | H_i(A_{is}) \preccurlyeq H_i(A_{it}) \}</script><p>Proposition 5和Remark 3可以共同完成将信息粒$G_{H_{i−1} L_{i−1}}$转化为$G_{H_i L_i}$的任务.</p>
<p>注意，对于一个给定的三支概念认知计算系统$F = \bigcup_{i=2}^n \{ F_{H_i L_i} \}$，所有信息粒$G_{H_1 L_1}, $事先是未知的。它们的顺序计算过程如下:</p>
<ol>
<li>根据公式$(10) \quad G_{HL} = \{ \langle H(A_i), LH(A_i)  \rangle | A_i \in Q(A) \} $，使用三支概念认知算子$H_1$和$L_1$来计算$G_{H_1 L_1}$。</li>
<li>根据Proposition 5和Remark 3，采用递归策略生成$G_{H_2 L_2}，…，G_{H_n L_n}$。</li>
</ol>
<p>算法1给出了求解该问题的具体步骤。时间复杂度分析如下。</p>
<p>假设$F = \bigcup_{i=2}^n \{ F_{H_i L_i} \}$是输入的三支概念认知计算系统。</p>
<p>运行第1步需要O (| A 1 | 2 | U 1  |)基于方程式的(10)和(18)。步骤3-1的时间复杂度为O (| A i | (| A i | 2 + | U i |))，步骤12-24的时间复杂度为O (| A  i | 2 | U i |)。因此，算法1的时间复杂度为O (n | a n | 2 (| a n | + | U n  |))，其中n为三向认知计算状态数。显然，它的时间复杂度是多项式的。</p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124114400737.png" srcset="/img/loading.gif" alt="image-20201124114400737"></p>
<p>最后，我们用一个例子来说明算法1。为了更好地理解这个例子，我们给出了生成$G_{H_i L_i}$的准备工作的一个充要条件。</p>
<p>可以构建一个三支概念认知计算状态$F_{H_{i} L_{i}} = (G_{H_{i-1} L_{i-1}}, H_{\triangle U_{i-1}}, H_{\triangle A_{i-1}})$，从而通过公式(16-18)获得三支粒概念$G_{H_i L_i}$，当且仅当以下条件具备：</p>
<ol>
<li>对象和属性被更新；</li>
<li>正确定义了评估函数$f_{A_i}$和阈值$\alpha, \beta$；</li>
<li>$Q(A_{i-1}) \le Q(A_i)$；</li>
<li>三支粒概念$G_{H_{i-1} L_{i-1}}$先前的状态已知；</li>
<li>信息粒$H_{i-1}, H_{\triangle U_{i-1}}, H_{\triangle A_{i-1}}$已知。</li>
</ol>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124152000855.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124152000855.png" srcset="/img/loading.gif" alt="image-20201124152000855"></p>
<p>则</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124152158269.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124152158269.png" srcset="/img/loading.gif" alt="image-20201124152158269"></p>
<ol>
<li><p>从Example 3 可知基于$H_1, L_1$的三支粒概念为</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124152555077.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124152555077.png" srcset="/img/loading.gif" alt="image-20201124152555077"></p>
<p>从中可以得到$H_1$的信息粒。</p>
</li>
<li><p>并且，由表二可知$H_{\triangle U_1}$的信息粒为</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124153121441.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124153121441.png" srcset="/img/loading.gif" alt="image-20201124153121441"></p>
<p>$H_{\triangle A_1}$的信息粒为</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124153321228.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124153321228.png" srcset="/img/loading.gif" alt="image-20201124153321228"></p>
</li>
<li><p>综上，一个三支概念认知计算状态$F_{H_2 L_2} = (G_{H_1 L_1}, H_{\triangle U_1}, H_{\triangle A_1})$可由公式$(16-18)$构建得到。详述如下：</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124153954366.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124153954366.png" srcset="/img/loading.gif" alt="image-20201124153954366"></p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124154202366.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124154202366.png" srcset="/img/loading.gif" alt="image-20201124154202366"></p>
</li>
</ol>
<p>此外，我们指出，这些三支粒概念也可以用于概念认知学习(详见下一节中的示例5和6)。</p>
<h2 id="4-Cognitive-processes"><a href="#4-Cognitive-processes" class="headerlink" title="4. Cognitive processes"></a>4. Cognitive processes</h2><p>通过认知计算[42]，得到的三支概念认知计算系统的三支粒状概念可以进一步用于根据给定的线索学习三支认知概念。</p>
<p>注意，线索可能是三支决策、一组属性类或两者都是。</p>
<p>从已知的线索中通过归纳、近似或推理而产生新的认知概念，一般称为认知过程。</p>
<p>例如，我们用例4来描述场景。假设$(\{x_1, x_4, x_5, x_7, x_{10} \}，\{x_2, x_3, x_6, x_9,  x_{11} \})$是一个可用的线索。那么，由什么知识引起的这种三方面的划分呢?从示例4很容易观察，没有直接回答这个问题,因为没有三支粒概念的外延正是$(\{x_1, x_4, x_5, x_7, x_{10} \}，\{x_2, x_3, x_6, x_9,  x_{11} \})$。在下面的文章中，我们试图找到这类问题的答案。</p>
<p>考虑到粗糙集理论中上下近似的思想被广泛应用于概念近似[14,37,38]，我们用这个思想来模拟认知过程。</p>
<p>在粗糙集理论[25]中，信息系统表示为$I = (U, A)$，其中每个对象$x∈U$在每个属性$a∈A$下都有一个值$a(x)$。</p>
<p>对于非空子集合$A_i \subset A$，定义了等价关系$IND(A_i)$为</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124162909724.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124162909724.png" srcset="/img/loading.gif" alt="image-20201124162909724"></p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124163036171.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124163036171.png" srcset="/img/loading.gif" alt="image-20201124163036171"></p>
<h3 id="4-1-Three-way-cognitive-concept-learning-from-three-way-decisions"><a href="#4-1-Three-way-cognitive-concept-learning-from-three-way-decisions" class="headerlink" title="4.1.  Three-way cognitive concept learning from three-way decisions"></a>4.1.  Three-way cognitive concept learning from three-way decisions</h3><p>基于上、下近似的思想，我们提出了一种从三向决策中学习一两个准确的近似三向认知概念的方法。</p>
<p>Definition 7. 设$F = \bigcup_{i=2}^n \{ F_{H_i L_i} \}$为三支概念认知计算系统，$G_{H_n L_n}$为$F$的三支粒概念，则三支决策$(X_0, Y_0)$的上下近似分别定义为</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124170816013.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124170816013.png" srcset="/img/loading.gif" alt="image-20201124170816013"></p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124171240279.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124171240279.png" srcset="/img/loading.gif" alt="image-20201124171240279"></p>
<p>由Definition 8 可知，当且仅当$\overline{Apr} (X_0, Y_0) = \underline{Apr} (X_0, Y_0)$时，$\alpha (X_0, Y_0) = 1$。在这种情况下，我们可以学习一个准确的三支认知概念；否则，学习两个近似的三支认知概念。算法2给出了从三支决策中学习认知概念的详细步骤。</p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124171901505.png" srcset="/img/loading.gif" alt="image-20201124171901505"></p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124172047110.png" srcset="/img/loading.gif" alt></p>
<p>Example 5. 假设原稿$x_1、x_4、x_5、x_7、x_{10}$被接受，而$x_2、x_3、x_6、x_9、x_{11}$被拒绝。那么审阅者(做出这样的三方决策)来自哪个领域呢?要回答这个问题,它需要学习三支认知概念从$X_0 = \{x_1, x_4, x_5, x_7, x_{10} \}$和$Y_0 = \{ x_2, x_3, x_6, x_9, x_{11} \}$基于$G_{L_2 H_2}$粒概念。由式(19)可得:</p>
<p>已知</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124173834628.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124173834628.png" srcset="/img/loading.gif" alt="image-20201124173834628"></p>
<p>则</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124173759539.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124173759539-1606739514447.png" srcset="/img/loading.gif" alt="image-20201124173759539"><br><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124174005721.png" srcset="/img/loading.gif" alt="image-20201124174005721"></p>
<h3 id="4-2-Three-way-cognitive-concept-learning-from-a-set-of-attribute-classes"><a href="#4-2-Three-way-cognitive-concept-learning-from-a-set-of-attribute-classes" class="headerlink" title="4.2. Three-way cognitive concept learning from a set of attribute classes"></a>4.2. Three-way cognitive concept learning from a set of attribute classes</h3><p>我们继续从一组属性类中学习一个确切的或两个近似的三支认知概念。</p>
<p>Definition 9. 设$F = \bigcup_{i=2}^n \{ F_{H_i L_i} \}$为一个三支概念认知计算系统，$G_{H_n L_n}$为$F$的三支粒概念，则$B_0 \in 2^{Q(A_n)}$的上下近似分别定义为</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124183948966.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124183948966.png" srcset="/img/loading.gif" alt="image-20201124183948966"></p>
<p>由Definition 10 可知，当且仅当$\overline{Apr} (B_0) = \underline{Apr} (B_0)$时，$\beta (B_0) = 1$。在这种情况下，我们可以学习一个准确的三支认知概念；否则，学习两个近似的三支认知概念。算法3给出了从一个属性类集合中学习认知概念的详细步骤。</p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124184753363.png" srcset="/img/loading.gif" alt="image-20201124184753363"></p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124184915684.png" srcset="/img/loading.gif" alt="image-20201124184915684"></p>
<p>Example 6. 领域1和领域2的审稿人$r_1, r_2, r_3, r_4, r_8$和$r_9$，哪些稿件被接受了，哪些被拒绝了?由于$A_{21} = \{ r_1, r_2, r_8 \}，A_{22}  = \{ r_3, r_4, r_9 \}$，那么$B_0 = \{ A_{21}, A_{22} \}$表示考虑的审阅者。另外，要回答上述问题，需要学习$B_0$的三支认知概念，因为$G_{L_2 H_2}$中没有粒概念，其内涵正好是$B_0$。通过式(20)，我们有</p>
<p>已知</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124173834628.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124173834628.png" srcset="/img/loading.gif" alt="image-20201124173834628"></p>
<p>则</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124190111377.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124190111377.png" srcset="/img/loading.gif" alt="image-20201124190111377"></p>
<p>因此，我们找到了一个确切的三向认知概念$\langle (\{x_1, x_4, x_5, x_{10} \}， \{x_2, x_3, x_6, x_{11} \})，\{A_{21}, A_{22} \} \rangle $从$ B_0$开始，与学习精度的$\beta (B_0) = 1$。换句话说，稿件$x_1、x_4、x_5、x_{10}$被1和2域的审稿人接受，而$x_2、x_3、x_6、x_{11}$被1和2域的审稿人拒绝。</p>
<h3 id="4-3-Three-way-cognitive-concept-learning-from-three-way-decisions-and-a-set-of-attribute-classes"><a href="#4-3-Three-way-cognitive-concept-learning-from-three-way-decisions-and-a-set-of-attribute-classes" class="headerlink" title="4.3 Three-way cognitive concept learning from three-way decisions and a set of attribute classes"></a>4.3 Three-way cognitive concept learning from three-way decisions and a set of attribute classes</h3><p>我们已经讨论了从三支决策以及一组属性类中学习三支认知概念的案例。然而，在现实世界中，可能会遇到三支决策和一组属性类同时可用的情况。下面将对这个问题进行研究。</p>
<p>Definition 11. 设$F = \bigcup_{i=2}^n \{ F_{H_i L_i} \}$为一个三支概念认知计算系统，$G_{H_n L_n}$为$F$的三支粒概念。对于三支决策$(X_0, Y_0)$和属性类$B_0 \in 2^{Q(A)}$，如果$\underline{Apr} (X_0, Y_0) \preccurlyeq H_n(B_0) \preccurlyeq \overline{Apr} (X_0, Y_0)$和$\underline{Apr} (B_0) \subseteq L_n(X_0, Y_0) \subseteq \overline{Apr} (B_0)$,我们说$(X_0, Y_0)$和$B_0$是联合概念诱导；否则，我们说它们是联合概念不可诱导的。</p>
<p>定义11将$(X_i, Y_i)$和$B_i (i∈S)$分为两类:可诱导概念对和不可诱导概念对。在接下来的内容中，我们只讨论可诱导概念对，因为不可诱导概念对彼此之间的联系较少。</p>
<p>Example 7.  在Example 5 中，$X_0 = \{x_1, x_4, x_5, x_7, x_{10} \}$和$Y_0 = \{ x_2, x_3, x_6, x_9, x_{11} \}$，$\underline{Apr}(X_0, Y_0) = ( \{ x_1, x_4, x_5, x_{10} \}, \{ x_2, x_3, x_6, x_{11} \})$和$\overline{Apr}(X_0, Y_0) = (\{ x_1, x_4, x_5, x_7, x_8, x_{10} \}, \{ x_2, x_3, x_6, x_9, x_{11}, x_{12} \})$，根据Definition 1的(iii)有$L_2(X_0, Y_0) = \{ A_{21}, A_{22} \}$，而且，在Example 6 中，$B_0 = \{ A_{21}, A_{22} \}, \underline{Apr}(B_0) = \{ A_{21}, A_{22} \}, \overline{Apr}(B_0) = \{ A_{21}, A_{22} \}$和$H_2(B_0) = (\{ x_1, x_4, x_5, x_{10} \}, \{ x_2, x_3, x_6, x_{11} \})$。那么根据Definition 11，我们知道$(X_0, Y_0)$和$ B_0$是联合概念可诱导的。</p>
<p>现在，我们讨论如何从概念诱导来学习三支认知概念。</p>
<p>Definition 12. 设$F = \bigcup_{i=2}^n \{ F_{H_i L_i} \}$为一个三支概念认知计算系统，$G_{H_n L_n}$为$F$的三支粒概念，对于三支决策$(X_0, Y_0)$和属性类$B_0 \in 2^{Q(A_n)}$，如果它们具有联合概念可诱导性，我们称之为</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124201949984.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124201949984.png" srcset="/img/loading.gif" alt="image-20201124201949984"></p>
<p>从Definition 12可知，$\gamma ((X_0, Y_0), B_0) = 1$当且仅当$\overline{Apr} (X_0, Y_0) = \underline{Apr} (X_0, Y_0)$和$\overline{Apr} (B_0) = \underline{Apr} (B_0)$，我们学习了一个精确的三支认知概念;否则，学习两个近似的三支认知概念。算法4展示了从三支决策和一组属性类中学习三支认知概念的详细过程。</p>

<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/images/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124202608051.png" srcset="/img/loading.gif" alt="image-20201124202608051"></p>
<p>Example 8. 从Example 7有$(X_0, Y_0) = (\{ x_1, x_4, x_5, x_7, x_{10} \}, \{ x_2, x_3, x_6, x_9, x_{11} \})$和$B_0 = \{ A_{21}, A_{22} \}$是联合概念可诱导的。并且，从Example 5有两个近似认知概念$\underline{Apr}(X_0, Y_0) = \langle (\{ x_1, x_4, x_5, x_{10} \}, \{ x_2, x_3, x_6, x_{11} \}), \{ A_{21}, A_{22}  \} \rangle$和$\overline{Apr}(X_0, Y_0) = \langle (\{ x_1, x_4, x_5, x_7, x_8, x_{10} \}, \{ x_2, x_3, x_6, x_9, x_{11}, x_{12} \}), \{ A_{21}, A_{22}, A_{23}  \} \rangle$学自于$(X_0, Y_0)$和$\alpha (X_0, Y_0) = \frac{6}{7}$。此外，从Example 6可以获得一个精确的三支认知概念$ \langle (\{ x_1, x_4, x_5, x_{10} \}, \{ x_2, x_3, x_6, x_{11} \}), \{ A_{21}, A_{22}  \} \rangle$学自于$B_0$和$\beta (B_0) = 1$。</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124211914376.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124211914376.png" srcset="/img/loading.gif" alt="image-20201124211914376"></p>
<h2 id="5-Numerical-experiments"><a href="#5-Numerical-experiments" class="headerlink" title="5. Numerical experiments"></a>5. Numerical experiments</h2><p>在本节中，我们将进行一些数值实验来评估所提出的学习方法的性能。</p>
<p>在实验中，我们从UCI机器学习知识库[8]中选取了五个数据集:the Letter Recognition dataset,<br>KEGG Metabolic Relation Network dataset, Skin Segmentation dataset, 3D Road Network dataset and Poker Hand dataset。表3描述了这些数据集的详细信息。在实验中，由于KEGG代谢关系网络数据集中的第一个属性“Pathway  text”具有符号性，因此我们将其排除在外。</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124213538190.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124213538190.png" srcset="/img/loading.gif" alt="image-20201124213538190"></p>
<p>为了生成标准数据集(例如，它们的属性都是布尔值)，一个数据预处理技术被应用到五个选定的数据集。详情见表4，其中” / “表示”不采取行动”，“Bisection”的意思是“把将每个属性的值从小到大分成两个长度相同的不相交区间”，而“分割成六个相等的区段”意味着“将每个属性的值从小到大分成六个长度相同的两两不相交区间”。并采用[46]缩放方法将其转换为标准数据集。在这里，我们用事实上是形式上下文的数据集1-5表示得到的标准数据集。</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124213740368.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201124213740368.png" srcset="/img/loading.gif" alt="image-20201124213740368"></p>
<p>TWCCS is the abbreviation of “Three-way cognitive computing system”.</p>
<p>In the table, $U_i = \{ p – q \}$ means that U i is constituted by the objects between the p th and q th objects including<br>the endpoints, so does $A_i$ .</p>
<p>将数据集1、2、3、4、5划分为不同的段，设计相应的三支概念认知计算系统：$F^{(1)} = \bigcup_{i=2}^{10} \{ F_{H_i L_i}^{(1)} \}, F^{(2)} = \bigcup_{i=2}^{6} \{ F_{H_i L_i}^{(2)} \}, F^{(3)} = \bigcup_{i=2}^{3} \{ F_{H_i L_i}^{(3)} \}, F^{(4)} = \bigcup_{i=2}^{3} \{ F_{H_i L_i}^{(3)} \}, F^{(5)} = \bigcup_{i=2}^{3} \{ F_{H_i L_i}^{(5)} \}$，</p>
<p>此外，我们还展示了如何$Q(A_{i−1}) ≤ Q(A_i) (i = 2,3，…，10)$在$F^{(1)}$中设计。具体来说，$Q(A_{(i-1)}) = \{A_{(i-1)1}, A_{(i-1)2}, A_{(i-1)3}, A_{(i-1)4}, A_{(i-1)5}, A_{(i-1)6} \}$。</p>
<p>$A_{(i-1)j} = \frac{|A_{i-1|}}{5}, (j=1, 2, 3, 4, 5)$而$A_{(i-1)6}$为5部分后剩余的。</p>
<p>$\triangle A_{i-1} = A_i - A_{i-1} = \{ \triangle A_{(i-1)1}, \triangle A_{(i-1)2}, \triangle A_{(i-1)3}, \triangle A_{(i-1)4}, \triangle A_{(i-1)5}, \triangle A_{(i-1)6} \}$</p>
<p>$\triangle A_{(i-1)j} = \frac{\triangle |A_{i-1|}}{5}, (j=1, 2, 3, 4, 5)$而$\triangle A_{(i-1)6}$为5部分后剩余的。</p>
<p>$Q(A_i) = \{ A_{i1}, A_{i2}, A_{i3}, A_{i4}, A_{i5}, A_{i6} \}$且$A_{ij} = A_{(i-1)j} \cup  \triangle A_{(i-1)j}$</p>
<p>所以$Q(A_{i−1}) ≤ Q(A_i)$，其余数据集处理类似。</p>
<p>实验中取$\alpha = \frac{3}{4}, \beta = \frac{1}{4}$，上面的标准数据集是标准形式背景，输入数据是1和0。</p>
<p>评价函数$f_{B_i}(x) = \frac{\cup (x=1)}{\cup (x=0)}, (B_i \in  2^{Q(A_i)})$</p>
<p>此外，为了保证顺序三支决策的顺利实施，在进入下一阶段的认知计算状态时，将前一阶段被划分为正区域和负区域的对象信息省略掉。</p>
<img src="/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201125174729284.png" srcset="/img/loading.gif" class>
<p><img src="/peerless.github.io/2020/11/21/2017-Information%20Sciences-Three-way%20cognitive%20concept%20learning%20via%20multi-granularity/image-20201125174729284.png" srcset="/img/loading.gif" alt="image-20201125174729284"></p>
<p>利用算法1,我们取得三支粒概念$G_{L_{10} H_{10}}^{(1)}, G_{L_{6} H_{6}}^{(2)}, G_{L_{3} H_{3}}^{(3)}, G_{L_{3} H_{3}}^{(4)}, G_{L_{3} H_{3}}^{(5)}$和三支概念认知计算系统$F^{(1)}, F^{(2)}, F^{(3)}, F^{(4)}, F^{(5)}$。因此，根据第4节的理论结果，这些粒概念可以进一步用于根据给定的线索学习三支认知概念。在不失一般性的前提下，我们对算法2、算法3、算法4随机生成100条线索，然后将算法2 -4应用于数据集1-5。在这里，算法2  -4被重复了10次，因为它们每次只能完成一个线索的学习任务。算法2-4的平均运行时间也如表6所示。从表中可以看出，即使对于最大的数据集，它们也都非常快。</p>
<h2 id="6-Final-remarks"><a href="#6-Final-remarks" class="headerlink" title="6. Final remarks"></a>6. Final remarks</h2><p>在这一节中，我们对全文做一些总结。</p>
<ol>
<li><p>我们工作的简要总结。为了揭示解决决策问题的三支概念的基本思想，我们讨论了基于多粒度的三支认知概念学习。</p>
<ol>
<li>首先提出了一种基于多粒度、三支决策原则的三支认知概念形成的公理化方法。</li>
<li>在此基础上，设计了一个用于学习复合三支粒概念认知的三支概念认知计算系统。</li>
<li>此外，我们还采用下近似和上近似的思想来模拟认知过程，从一个给定的线索中学习三支认知概念。</li>
<li><p>最后，进行了数值实验来评估所提出的学习方法的性能。</p>
<p>2.我们研究的意义。</p>
</li>
<li><p>我们注意到，已有的文献中提出了许多不同类型的三支概念，每一种都有不同的性质。</p>
</li>
<li>为了理解三支概念的基本决策机制，有必要确定表征三支概念的内在属性。</li>
<li><p>利用多粒度和三支决策原则，我们的研究成功地阐明了三个性质，它们可以共同用作描述三支概念的公理。此外，如2.2节所讨论的，这些内在属性具有显式语义。</p>
<p>3.我们的方法的优点。</p>
</li>
<li><p>我们设计了一个学习粒概念的三支概念认知计算系统，并提出了模拟认知过程的概念学习方法。</p>
</li>
<li>我们的三支概念认知计算系统可以随着对象和属性的增加而更新三支粒概念。</li>
<li>此外，提出的概念学习方法有助于从已知线索记忆三支认知概念。</li>
<li><p>另外，从第5节的实验可以看出，我们的学习方法是非常高效的；对于超过100万个实例的数据集，它们只需要不到200秒的时间。因此，如果能够成功开发出一些并行计算技术，我们的方法就有可能应用于大数据领域。</p>
<p>4.我们的研究与现有研究的异同。</p>
</li>
<li><p>本文采用顺序三支决策的思想，建立了构建三支概念的公理化方法。</p>
</li>
<li>将粒计算融入到三元认知概念中，构建信息粒，保证了三元认知概念的定义，并可用于从给定的线索记忆新的认知概念。</li>
<li><p>此外，本文提出的三支认知算子$H$和$L$在$2^{Q (A)}$和$T(U)$之间形成了保序伽罗瓦连接。因此，它们与经典的认知算子[16]完全不同，[16]在$2^{A}$和$2^{U}$之间形成了反序伽罗瓦连接。换句话说，这两种认知操作者具有不同的认知机制。</p>
<p>然而，我们的研究与已有的研究有一些相似之处。例如，为了支持顺序的三支决策，多粒度被设计为单调性，在信息更新过程中通过$Q(A_{i-1})≤Q(A_i)$来实现。与往常一样，我们的顺序三支决策也从上一个三支概念认知计算状态到下一个三支概念认知计算状态变得越来越有效。如果信息可以不断更新，我们连续的三向决策的最终结果将退化为双向决策(即，边界区域消失)。</p>
<p>5.进一步研究的展望。</p>
</li>
<li><p>注意，经典的认知操作符已经被重新考虑以适应大数据环境[14]。事实上，这种问题在三支认知算子中也同样存在。</p>
</li>
<li>因此，需要重新设计三支认知算子，以满足大数据的不同需求，如大规模、多源、异构数据。</li>
<li>此外，我们认为，在三支概念认知计算系统中引入认知逻辑，可以有效地模拟人脑的学习、推理等行为。这些问题将在我们今后的工作中进行研究。</li>
</ol>
</li>
</ol>
<p>词伙积累：</p>
<ul>
<li>if there exists … such that …, then … ：如果存在…使得…，那么…。</li>
<li>dealt with in a manner similar to F (1) , which is omitted here for convenience of presentation：以类似F(1)的方式处理，为了便于介绍，这里省略了。</li>
<li>Without loss of generality：在不失一般性的前提下。</li>
<li>The authors would like to thank the reviewers for their valuable comments and helpful suggestions which lead to a significant improvement on the manuscript. This work was supported by the …</li>
</ul>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AE%BA%E6%96%87/%E6%A6%82%E5%BF%B5%E8%AE%A4%E7%9F%A5%E5%AD%A6%E4%B9%A0/">概念认知学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E4%B8%89%E6%94%AF%E7%B2%92%E6%A6%82%E5%BF%B5/">三支粒概念</a>
                    
                      <a class="hover-with-bg" href="/tags/%E6%A6%82%E5%BF%B5%E8%AE%A4%E7%9F%A5%E5%AD%A6%E4%B9%A0/">概念认知学习</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%A4%9A%E7%B2%92%E5%BA%A6/">多粒度</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/12/10/2020-JAIHC-An%20interactive%20role%20learning%20and%C2%A0discovery%20model%20for%C2%A0multi%E2%80%91department%20%20RBAC%20building%20based%20on%C2%A0attribute%20exploration/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">2020-JAIHC-An interactive role learning and discovery model for multi‑department  RBAC building based on attribute exploration</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/10/27/2020-IEEE%20TKDE-Semi-supervised%20Concept%20Learning%20by%20Concept-cognitive%20Learning%20and%20Concept%20Space/">
                        <span class="hidden-mobile">2020-IEEE TKDE-Semi-supervised Concept Learning by Concept-cognitive Learning and Concept Space</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "RcI3ePX6qkbdKOX0xjPq8Xy3-gzGzoHsz",
          app_key: "suQG3XDbcx2bpMJLeuKCcqS7",
          placeholder: "由于作者水平有限，加上时间仓促，文中难免存在不足之处，敬请读者批评指正。",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: false,
          serverURLs: "https://rci3epx6.lc-cn-n1-shared.com",
        });
      });
    }
    createObserver(loadValine, 'vcomments');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <!--
 * @Author: your name
 * @Date: 2020-06-04 05:16:36
 * @LastEditTime: 2020-07-04 16:26:58
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: \blog\themes\fluid\layout\_partial\footer.ejs
--> 
<footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://github.com/SuperficialJ/peerless.github.io." target="_blank" rel="nofollow noopener"><span>peerless</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    <!--
 * @Author: your name
 * @Date: 2020-06-28 18:23:11
 * @LastEditTime: 2020-07-04 16:28:28
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: \peer-less.github.io\themes\fluid\layout\_partial\statistics.ejs
--> 

  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: inline-block">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: inline-block">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


    

    
  </div>

  <p id="hitokoto" align='center'>:D 获取中...</p>
  <script>
    fetch('https://v1.hitokoto.cn')
      .then(response => response.json())
      .then(data => {
        const hitokoto = document.getElementById('hitokoto')
        hitokoto.innerText = data.hitokoto
        })
        .catch(console.error)
  </script>

  <div align='center'>
    <span id="timeDate">载入天数...</span>
    <span id="times">载入时分秒...</span>
    <script>
    var now = new Date();
    function createtime(){
        var grt= new Date("06/26/2020 22:53:55");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24;
        dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
        hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){
            hnum = "0" + hnum;
        }
        minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes);
        if(String(mnum).length ==1 ){
                  mnum = "0" + mnum;
        }
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds);
        if(String(snum).length ==1 ){
                  snum = "0" + snum;
        }
        document.getElementById("timeDate").innerHTML = "本站安全运行&nbsp"+dnum+"&nbsp天";
        document.getElementById("times").innerHTML = hnum + "&nbsp小时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
    }
    setInterval("createtime()",250);
    </script>
  </div>

  
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "2017-Information Sciences-Three-way cognitive concept learning via multi-granularity&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  



  
  
    <script type="text/javascript">
      //定义获取词语下标
      var a_idx = 0;
      jQuery(document).ready(function ($) {
        //点击body时触发事件
        $("body").click(function (e) {
          //需要显示的词语
          var a = new Array("富强", "民主", "文明", "和谐", "自由", "平等", "公正", "法治", "爱国", "敬业", "诚信", "友善");
          //设置词语给span标签
          var $i = $("<span/>").text(a[a_idx]);
          //下标等于原来下标+1  余 词语总数
          a_idx = (a_idx + 1) % a.length;
          //获取鼠标指针的位置，分别相对于文档的左和右边缘。
          //获取x和y的指针坐标
          var x = e.pageX, y = e.pageY;
          //在鼠标的指针的位置给$i定义的span标签添加css样式
          $i.css({
            "z-index": 999,
            "top": y - 20,
            "left": x,
            "position": "absolute",
            "font-weight": "bold",
            "color": rand_color()
          });
          // 随机颜色
          function rand_color() {
            return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
          }
          //在body添加这个标签
          $("body").append($i);
          //animate() 方法执行 CSS 属性集的自定义动画。
          //该方法通过CSS样式将元素从一个状态改变为另一个状态。CSS属性值是逐渐改变的，这样就可以创建动画效果。
          //详情请看http://www.w3school.com.cn/jquery/effect_animate.asp
          $i.animate({
            //将原来的位置向上移动180
            "top": y - 180,
            "opacity": 0
            //1500动画的速度
          }, 1500, function () {
            //时间到了自动删除
            $i.remove();
          });
        });
      })
      ;
    </script>
  











  

  

  

  

  

  





</body>
</html>
